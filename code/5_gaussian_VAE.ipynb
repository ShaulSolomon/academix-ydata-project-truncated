{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting elasticsearch\n",
      "  Using cached elasticsearch-7.8.0-py2.py3-none-any.whl (188 kB)\n",
      "Requirement already satisfied: certifi in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from elasticsearch) (2020.4.5.2)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from elasticsearch) (1.25.9)\n",
      "Installing collected packages: elasticsearch\n",
      "Successfully installed elasticsearch-7.8.0\n",
      "Collecting elasticsearch_dsl\n",
      "  Using cached elasticsearch_dsl-7.2.1-py2.py3-none-any.whl (53 kB)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from elasticsearch_dsl) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from elasticsearch_dsl) (2.8.1)\n",
      "Requirement already satisfied: elasticsearch<8.0.0,>=7.0.0 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from elasticsearch_dsl) (7.8.0)\n",
      "Requirement already satisfied: certifi in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from elasticsearch<8.0.0,>=7.0.0->elasticsearch_dsl) (2020.4.5.2)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from elasticsearch<8.0.0,>=7.0.0->elasticsearch_dsl) (1.25.9)\n",
      "Installing collected packages: elasticsearch-dsl\n",
      "Successfully installed elasticsearch-dsl-7.2.1\n",
      "Collecting pymed\n",
      "  Using cached pymed-0.8.9-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: requests>=2.20.0 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from pymed) (2.23.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from requests>=2.20.0->pymed) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from requests>=2.20.0->pymed) (2020.4.5.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from requests>=2.20.0->pymed) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from requests>=2.20.0->pymed) (2.9)\n",
      "Installing collected packages: pymed\n",
      "Successfully installed pymed-0.8.9\n",
      "Collecting gensim\n",
      "  Using cached gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2 MB)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied: six>=1.5.0 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from gensim) (1.15.0)\n",
      "Processing /home/ubuntu/.cache/pip/wheels/a4/9b/d5/85705a7ab783cd6f7bd718f01d3b1396272f30044e3c36401a/smart_open-2.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from gensim) (1.3.2)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.23.0)\n",
      "Requirement already satisfied: boto in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: boto3 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (1.14.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.4.5.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2.9)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.5 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.17.5)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.10.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.5->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.5->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-3.8.3 smart-open-2.1.0\n",
      "Collecting torchsummary\n",
      "  Using cached torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    }
   ],
   "source": [
    "USE_SERVER = True\n",
    "if USE_SERVER:\n",
    "    !pip install elasticsearch\n",
    "    !pip install elasticsearch_dsl\n",
    "    !pip install pymed\n",
    "    !pip install gensim\n",
    "    !pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import pandas as pd\n",
    "import utils\n",
    "import os\n",
    "from utils import PROJECT_ROOT, DATA_PATH\n",
    "import yuval_module.paper_source as PaperSource\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import py_4.get_mesh_vec as get_mesh_vec\n",
    "import py_3.sim_matrix_3 as sim_matrix_3\n",
    "import py_4.get_all_features as get_all_features \n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_embed=get_mesh_vec.MeshEmbeddings(PROJECT_ROOT + \"data/mesh_data/MeSHFeatureGeneratedByDeepWalk.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PULLING FROM S3\n",
      "FILE PULLED\n"
     ]
    }
   ],
   "source": [
    "FILE = \"enriched_labeled_dataset_large\" \n",
    "if os.path.exists(PROJECT_ROOT + DATA_PATH + FILE):\n",
    "    print(\"READING FROM LOCAL\")\n",
    "    if FILE.split(\".\")[1] == \"json\":\n",
    "        df = pd.read_json(PROJECT_ROOT + DATA_PATH + FILE)\n",
    "    else:\n",
    "        df = pd.read_csv(PROJECT_ROOT + DATA_PATH + FILE)\n",
    "    #ps = PaperSource()\n",
    "else:\n",
    "    print(\"PULLING FROM S3\")\n",
    "    ps = sim_matrix_3.load_dataset(FILE)\n",
    "    df = ps.get_dataset()\n",
    "\n",
    "df.drop(columns=[\"last_author_country\"],inplace=True)\n",
    "df.rename(columns={'ORG_STATE':'last_author_country'},inplace=True)\n",
    "\n",
    "print(\"FILE PULLED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/AYP\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_core = pd.read_csv(\"data/train_set_author_names.csv\")[\"0\"]\n",
    "auth_eps = pd.read_csv(\"data/val_set_author_names.csv\")[\"0\"]\n",
    "auth_usecase = pd.read_csv(\"data/test_set_author_names.csv\")[\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_train = list(set(df['last_author_name']) - set(auth_usecase))[:4000]\n",
    "selection_test = list(set(df['last_author_name']) - set(auth_usecase))[4000:4500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#settings\n",
    "\n",
    "BATCH_SIZE= 32\n",
    "EPOCHS = 30\n",
    "cuda = torch.cuda.is_available()\n",
    "seed = 42\n",
    "log_interval = 10\n",
    "num_workers = 2\n",
    "\n",
    "#check for cuda\n",
    "device = torch.device('cuda' if cuda else 'cpu')\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'/home/ubuntu/AYP/code/models/names_epochs_2_vectorSize_64_window_2.model' already exits. Using existing model to re-generate results.\n",
      "'/home/ubuntu/AYP/code/models/co_authors_epochs_2_vectorSize_64_window_2.model' already exits. Using existing model to re-generate results.\n"
     ]
    }
   ],
   "source": [
    "all_vae = get_all_features.VAE_Features(df)\n",
    "df_nonan = df[np.invert(df['mesh'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDS(Dataset):\n",
    "    def __init__(self,df,selection,vae_features = None):\n",
    "        super().__init__()\n",
    "        self.df = df[df['last_author_name'].isin(selection)]\n",
    "        if vae_features is None:\n",
    "            print(\"Creating new VAE FEATURES\")\n",
    "            self.vae_features = get_all_features.VAE_Features(self.df)\n",
    "        else:\n",
    "            print(\"Using pre-defined VAE FEATURES\")\n",
    "            self.vae_features = vae_features\n",
    "        self.features = self.vae_features.get_all_features(self.df)\n",
    "        print(list(self.vae_features.mesh_features.mesh_missing))\n",
    "        self.input_dim = self.vae_features.input_dims\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        features = self.features[idx]\n",
    "        return features\n",
    "    \n",
    "    def __getvae__(self):\n",
    "        return self.vae_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pre-defined VAE FEATURES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/AYP/code/py_4/get_all_features.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['co_authors']=df.authors.apply( lambda x: [i['name'] for i in x] )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining new scaler\n",
      "['MESH NAME NOT FOUND: Illicit Drugs', 'MESH NAME NOT FOUND: Male', 'MESH NAME NOT FOUND: Reinforcement, Psychology', 'MESH NAME NOT FOUND: Phospholipid Hydroperoxide Glutathione Peroxidase', 'MESH NAME NOT FOUND: Infections', 'MESH NAME NOT FOUND: Chlorocebus aethiops', 'MESH NAME NOT FOUND: Recognition, Psychology', 'MESH NAME NOT FOUND: Dependency, Psychological', 'MESH NAME NOT FOUND: mTOR Associated Protein, LST8 Homolog', \"MESH NAME NOT FOUND: Practice Patterns, Physicians'\", 'MESH NAME NOT FOUND: Conditioning, Psychological', 'MESH NAME NOT FOUND: Outcome Assessment, Health Care', 'MESH NAME NOT FOUND: Diet, Healthy', 'MESH NAME NOT FOUND: RNA, Circular', 'MESH NAME NOT FOUND: Outcome and Process Assessment, Health Care', 'MESH NAME NOT FOUND: Inhibition, Psychological', 'MESH NAME NOT FOUND: Phosphoinositide-3 Kinase Inhibitors', 'MESH NAME NOT FOUND: Female', 'MESH NAME NOT FOUND: Confounding Factors, Epidemiologic']\n"
     ]
    }
   ],
   "source": [
    "train_set = ToyDS(df_nonan, selection_train, all_vae)\n",
    "train_loader=DataLoader(dataset= train_set, batch_size = BATCH_SIZE, shuffle = True, num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_GAUSSIAN(nn.Module):\n",
    "    def __init__(self, hidden_dim, latent_dim, input_dim = train_set.input_dim):\n",
    "        super(VAE_GAUSSIAN, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.fc1 = nn.Linear(self.input_dim, self.hidden_dim)\n",
    "        self.fc21 = nn.Linear(self.hidden_dim, self.latent_dim)\n",
    "        self.fc22 = nn.Linear(self.hidden_dim, self.latent_dim)\n",
    "        self.fc3 = nn.Linear(self.latent_dim, self.hidden_dim)\n",
    "        self.fc4 = nn.Linear(self.hidden_dim, self.input_dim)\n",
    "        self.fc5 = nn.Linear(self.hidden_dim, self.input_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc21(h), self.fc22(h)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu) # return z sample\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc3(z))\n",
    "        mu = self.fc4(h)\n",
    "        logvar = self.fc5(h)\n",
    "        return mu, logvar\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu_latent, logvar_latent = self.encode(x.view(-1, self.input_dim))\n",
    "        z = self.reparameterize(mu_latent, logvar_latent)\n",
    "        mu_x, logvar_x = self.decode(z)\n",
    "        return mu_latent, logvar_latent, mu_x, logvar_x\n",
    "    \n",
    "def loss_function_gaussian(x, mu_x, logvar_x, mu_latent, logvar_latent):\n",
    "    # neg log likelihood of x under normal\n",
    "    loss_rec = np.log(2.0 * np.pi) + logvar_x + (x - mu_x)**2 / (2*torch.exp(logvar_x))\n",
    "    KLD = -0.5 * torch.sum(1 + logvar_latent - mu_latent.pow(2) - logvar_latent.exp())\n",
    "    return torch.mean(loss_rec) + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gaussian = VAE_GAUSSIAN(hidden_dim=32,latent_dim=2).to(device)\n",
    "optimizer_gaussian = optim.Adam(model_gaussian.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_gaussian(tr_loader, model, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    train_log = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Started training epoch no. {}\".format(epoch+1))\n",
    "        train_loss= 0\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            data = data.to(device, dtype=torch.float32)\n",
    "            optimizer.zero_grad()\n",
    "            mu_latent, logvar_latent, mu_x, logvar_x = model(data)\n",
    "            loss = criterion(data, mu_x, logvar_x, mu_latent, logvar_latent)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        print('====> Epoch: {} Average loss: {:.8f}\\n'.format(\n",
    "            epoch+1, train_loss / len(train_loader.dataset)))\n",
    "        train_log.append({\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_loss / len(train_loader.dataset)})\n",
    "    return train_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_gaussian(test_loader, model):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            data = data.to(device, dtype=torch.float32)\n",
    "            mu_latent, logvar_latent, mu_x, logvar_x = model(data)\n",
    "            test_loss += loss_function_gaussian(data, mu_x, logvar_x, mu_latent, logvar_latent).item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training epoch no. 1\n",
      "====> Epoch: 1 Average loss: 0.06710437\n",
      "\n",
      "Started training epoch no. 2\n",
      "====> Epoch: 2 Average loss: 0.06710505\n",
      "\n",
      "Started training epoch no. 3\n",
      "====> Epoch: 3 Average loss: 0.06709810\n",
      "\n",
      "Started training epoch no. 4\n",
      "====> Epoch: 4 Average loss: 0.06709752\n",
      "\n",
      "Started training epoch no. 5\n",
      "====> Epoch: 5 Average loss: 0.06708708\n",
      "\n",
      "Started training epoch no. 6\n",
      "====> Epoch: 6 Average loss: 0.06709964\n",
      "\n",
      "Started training epoch no. 7\n",
      "====> Epoch: 7 Average loss: 0.06709679\n",
      "\n",
      "Started training epoch no. 8\n",
      "====> Epoch: 8 Average loss: 0.06709542\n",
      "\n",
      "Started training epoch no. 9\n",
      "====> Epoch: 9 Average loss: 0.06709653\n",
      "\n",
      "Started training epoch no. 10\n",
      "====> Epoch: 10 Average loss: 0.06708962\n",
      "\n",
      "Started training epoch no. 11\n",
      "====> Epoch: 11 Average loss: 0.06708955\n",
      "\n",
      "Started training epoch no. 12\n",
      "====> Epoch: 12 Average loss: 0.06709564\n",
      "\n",
      "Started training epoch no. 13\n",
      "====> Epoch: 13 Average loss: 0.06709066\n",
      "\n",
      "Started training epoch no. 14\n",
      "====> Epoch: 14 Average loss: 0.06710166\n",
      "\n",
      "Started training epoch no. 15\n",
      "====> Epoch: 15 Average loss: 0.06708848\n",
      "\n",
      "Started training epoch no. 16\n",
      "====> Epoch: 16 Average loss: 0.06709206\n",
      "\n",
      "Started training epoch no. 17\n",
      "====> Epoch: 17 Average loss: 0.06708901\n",
      "\n",
      "Started training epoch no. 18\n",
      "====> Epoch: 18 Average loss: 0.06709735\n",
      "\n",
      "Started training epoch no. 19\n",
      "====> Epoch: 19 Average loss: 0.06709555\n",
      "\n",
      "Started training epoch no. 20\n",
      "====> Epoch: 20 Average loss: 0.06709085\n",
      "\n",
      "Started training epoch no. 21\n",
      "====> Epoch: 21 Average loss: 0.06709728\n",
      "\n",
      "Started training epoch no. 22\n",
      "====> Epoch: 22 Average loss: 0.06708318\n",
      "\n",
      "Started training epoch no. 23\n",
      "====> Epoch: 23 Average loss: 0.06708767\n",
      "\n",
      "Started training epoch no. 24\n",
      "====> Epoch: 24 Average loss: 0.06708990\n",
      "\n",
      "Started training epoch no. 25\n",
      "====> Epoch: 25 Average loss: 0.06708816\n",
      "\n",
      "Started training epoch no. 26\n",
      "====> Epoch: 26 Average loss: 0.06708553\n",
      "\n",
      "Started training epoch no. 27\n",
      "====> Epoch: 27 Average loss: 0.06709841\n",
      "\n",
      "Started training epoch no. 28\n",
      "====> Epoch: 28 Average loss: 0.06708499\n",
      "\n",
      "Started training epoch no. 29\n",
      "====> Epoch: 29 Average loss: 0.06708584\n",
      "\n",
      "Started training epoch no. 30\n",
      "====> Epoch: 30 Average loss: 0.06709484\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'epoch': 0, 'train_loss': 0.06710437422197064},\n",
       " {'epoch': 1, 'train_loss': 0.06710505465640122},\n",
       " {'epoch': 2, 'train_loss': 0.06709810451433046},\n",
       " {'epoch': 3, 'train_loss': 0.0670975201881108},\n",
       " {'epoch': 4, 'train_loss': 0.06708707719571705},\n",
       " {'epoch': 5, 'train_loss': 0.06709963773432416},\n",
       " {'epoch': 6, 'train_loss': 0.06709679189559456},\n",
       " {'epoch': 7, 'train_loss': 0.06709542422747979},\n",
       " {'epoch': 8, 'train_loss': 0.06709652663693245},\n",
       " {'epoch': 9, 'train_loss': 0.06708962272627565},\n",
       " {'epoch': 10, 'train_loss': 0.06708954922763108},\n",
       " {'epoch': 11, 'train_loss': 0.06709563706986467},\n",
       " {'epoch': 12, 'train_loss': 0.06709065724266464},\n",
       " {'epoch': 13, 'train_loss': 0.06710166200437374},\n",
       " {'epoch': 14, 'train_loss': 0.0670884842082221},\n",
       " {'epoch': 15, 'train_loss': 0.0670920619672969},\n",
       " {'epoch': 16, 'train_loss': 0.0670890144037228},\n",
       " {'epoch': 17, 'train_loss': 0.06709734993760823},\n",
       " {'epoch': 18, 'train_loss': 0.06709555133607434},\n",
       " {'epoch': 19, 'train_loss': 0.06709085023146294},\n",
       " {'epoch': 20, 'train_loss': 0.06709728248339482},\n",
       " {'epoch': 21, 'train_loss': 0.06708317976054566},\n",
       " {'epoch': 22, 'train_loss': 0.06708767124685887},\n",
       " {'epoch': 23, 'train_loss': 0.06708990295265792},\n",
       " {'epoch': 24, 'train_loss': 0.06708815664452317},\n",
       " {'epoch': 25, 'train_loss': 0.06708553442048996},\n",
       " {'epoch': 26, 'train_loss': 0.0670984096791112},\n",
       " {'epoch': 27, 'train_loss': 0.0670849858576423},\n",
       " {'epoch': 28, 'train_loss': 0.06708584172686005},\n",
       " {'epoch': 29, 'train_loss': 0.0670948436110078}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch_gaussian(train_loader,model_gaussian,loss_function_gaussian,optimizer_gaussian,num_epochs= EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pre-defined VAE FEATURES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/AYP/code/py_4/get_all_features.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['co_authors']=df.authors.apply( lambda x: [i['name'] for i in x] )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using old scaler\n",
      "['MESH NAME NOT FOUND: Illicit Drugs', 'MESH NAME NOT FOUND: Male', 'MESH NAME NOT FOUND: Reinforcement, Psychology', 'MESH NAME NOT FOUND: Phospholipid Hydroperoxide Glutathione Peroxidase', 'MESH NAME NOT FOUND: Infections', 'MESH NAME NOT FOUND: Chlorocebus aethiops', 'MESH NAME NOT FOUND: Recognition, Psychology', 'MESH NAME NOT FOUND: Dependency, Psychological', 'MESH NAME NOT FOUND: mTOR Associated Protein, LST8 Homolog', \"MESH NAME NOT FOUND: Practice Patterns, Physicians'\", 'MESH NAME NOT FOUND: Conditioning, Psychological', 'MESH NAME NOT FOUND: Outcome Assessment, Health Care', 'MESH NAME NOT FOUND: Diet, Healthy', 'MESH NAME NOT FOUND: RNA, Circular', 'MESH NAME NOT FOUND: Outcome and Process Assessment, Health Care', 'MESH NAME NOT FOUND: Mitophagy', 'MESH NAME NOT FOUND: Inhibition, Psychological', 'MESH NAME NOT FOUND: Phosphoinositide-3 Kinase Inhibitors', 'MESH NAME NOT FOUND: Female', 'MESH NAME NOT FOUND: Confounding Factors, Epidemiologic']\n"
     ]
    }
   ],
   "source": [
    "test_set = ToyDS(df_nonan, selection_test, vae_features = train_set.__getvae__())\n",
    "test_loader=DataLoader(dataset= test_set, batch_size = BATCH_SIZE, shuffle = True, num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0670\n"
     ]
    }
   ],
   "source": [
    "test_model_gaussian(test_loader, model_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.from_numpy(test_set.features).to(device,dtype=torch.float32)\n",
    "mu_latent, logvar_latent, mu_x, logvar_x = model_gaussian(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(test_set.features.shape==mu_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.992902788039997"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.square(mu_x.detach().cpu().numpy() - test_set.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_aws_neuron_pytorch_p36)",
   "language": "python",
   "name": "conda_aws_neuron_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

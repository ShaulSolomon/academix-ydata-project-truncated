{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgranit/academix-ydata-project/blob/master/code/3_Logisitic_Regression_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAW59VYVLUIJ",
        "colab_type": "code",
        "outputId": "45c65b2d-4843-49fd-8785-fe19d986ef76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# import os, urllib, glob, sys\n",
        "# from getpass import getpass\n",
        "\n",
        "# user = input('User name: ')\n",
        "# password = getpass('Password: ')\n",
        "# password = urllib.parse.quote(password) # your password is converted into url format\n",
        "# cmd_string = \"! git clone https://{0}:{1}@github.com/rgranit/academix-ydata-project AYP\".format(user, password)\n",
        "\n",
        "# os.system(cmd_string)\n",
        "# cmd_string, password = \"\", \"\" # removing the password from the variable\n",
        "\n",
        "# %cd ./AYP/code"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User name: ShaulSolomon\n",
            "Password: ··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "C:\\Users\\shaul\\Documents\\GitHub\\academix-ydata-project\\code\\py_3\\sim_matrix_3.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5hAha94LkS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, re, sys\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from yuval_module.paper_clusterer import PaperClusterer\n",
        "from yuval_module.paper_source import PaperSource\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression as LogR\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.cluster import DBSCAN as DBS\n",
        "from collections import Counter \n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from collections import defaultdict\n",
        "\n",
        "import py_3.sim_matrix_3 as sim_matrix_3\n",
        "import py_3.lr_model_3 as lr_model_3\n",
        "import py_3.db_scan_3 as db_scan_3\n",
        "\n",
        "import metric_eval_2\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import utils\n",
        "from utils import PROJECT_ROOT, DATA_PATH\n",
        "#DATA_PATH = DATA_PATH + \"labeled_data/\"\n",
        "FILE = \"enriched_labeled_dataset.json\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "READING FROM LOCAL\n"
        }
      ],
      "source": [
        "if os.path.exists(PROJECT_ROOT + DATA_PATH + FILE):\n",
        "    print(\"READING FROM LOCAL\")\n",
        "    if FILE.split(\".\")[1] == \"json\":\n",
        "        df = pd.read_json(PROJECT_ROOT + DATA_PATH + FILE)\n",
        "    else:\n",
        "        df = pd.read_csv(PROJECT_ROOT + DATA_PATH + FILE)\n",
        "    ps = PaperSource()\n",
        "else:\n",
        "    print(\"PULLING FROM S3\")\n",
        "    ps = sim_matrix_3.load_dataset(\"enriched_labeled_dataset\")\n",
        "    df = ps.get_dataset()\n",
        "\n",
        "df.drop(columns=[\"last_author_country\"],inplace=True)\n",
        "df.rename(columns={'ORG_STATE':'last_author_country'},inplace=True)"
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Establishing Use Cases\n",
        "\n",
        "As a precedent, we need to use the same authors to create the LR model, and these authors can't be used for the DBScan either (to ensure there isnt overfitting.)\n",
        "\n",
        "Taking the first 20 most prolific authors, we have a combined 788 papers, leading to 31K pairs (reduced from total amount to have a balanced set of same and dif author pairs).\n",
        "\n",
        "WE CAN ADD MORE IF WE NEED, THERE ARE 25K DISTINCT AUTHORS\n",
        "\n",
        "For use cases, we have:<br>\n",
        "    1. UA case (top 20 UA authors) // use_case = \"base_ua\"<br>\n",
        "    2. DA case (3 DA's where each publisher has at least 4 papers)// use_case = \"base_da\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_core = sim_matrix_3.base_authors(df,use_case = \"base_da\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Total number of papers:  180\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  32400\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nRemoving Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  16110\n"
        }
      ],
      "source": [
        "#Get Similarity matrix\n",
        "df_core, scaler = sim_matrix_3.get_similarity_matrix(ps,df_core,scaler=None,flag_base=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "29569306, 19490895"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "[[{'forename': 'Guolin',\n   'affiliation': 'Institute of Biosciences and Technology, College of Medicine, Texas A&M University, 2121 W Holcombe Blvd, Houston, TX, 77030, USA.',\n   'initials': 'G',\n   'name': 'Ma, G',\n   'lastname': 'Ma'},\n  {'forename': 'Jindou',\n   'affiliation': 'Beijing Key Laboratory of Gene Resource and Molecular, Development, College of Life Sciences, Beijing Normal University, Beijing, 100875, China.',\n   'initials': 'J',\n   'name': 'Liu, J',\n   'lastname': 'Liu'},\n  {'forename': 'Yuepeng',\n   'affiliation': 'Institute of Biosciences and Technology, College of Medicine, Texas A&M University, 2121 W Holcombe Blvd, Houston, TX, 77030, USA.',\n   'initials': 'Y',\n   'name': 'Ke, Y',\n   'lastname': 'Ke'},\n  {'forename': 'Xin',\n   'affiliation': 'Institute of Biosciences and Technology, College of Medicine, Texas A&M University, 2121 W Holcombe Blvd, Houston, TX, 77030, USA.',\n   'initials': 'X',\n   'name': 'Liu, X',\n   'lastname': 'Liu'},\n  {'forename': 'Minyong',\n   'affiliation': 'Department of Medicinal Chemistry, Key Laboratory of Chemical Biology, School of Pharmacy, Shandong University, Jinan, Shandong, 250012, China.',\n   'initials': 'M',\n   'name': 'Li, M',\n   'lastname': 'Li'},\n  {'forename': 'Fen',\n   'affiliation': 'Institute of Biosciences and Technology, College of Medicine, Texas A&M University, 2121 W Holcombe Blvd, Houston, TX, 77030, USA.',\n   'initials': 'F',\n   'name': 'Wang, F',\n   'lastname': 'Wang'},\n  {'forename': 'Gang',\n   'affiliation': 'Department of Biochemistry and Molecular Pharmacology, University of Massachusetts Medical School, Worcester, MA, 01605, USA.',\n   'initials': 'G',\n   'name': 'Han, G',\n   'lastname': 'Han'},\n  {'forename': 'Yun',\n   'affiliation': 'Institute of Biosciences and Technology, College of Medicine, Texas A&M University, 2121 W Holcombe Blvd, Houston, TX, 77030, USA.',\n   'initials': 'Y',\n   'name': 'Huang, Y',\n   'lastname': 'Huang'},\n  {'forename': 'Youjun',\n   'affiliation': 'Beijing Key Laboratory of Gene Resource and Molecular, Development, College of Life Sciences, Beijing Normal University, Beijing, 100875, China.',\n   'initials': 'Y',\n   'name': 'Wang, Y',\n   'lastname': 'Wang'},\n  {'forename': 'Yubin',\n   'affiliation': 'Institute of Biosciences and Technology, College of Medicine, Texas A&M University, 2121 W Holcombe Blvd, Houston, TX, 77030, USA.',\n   'initials': 'Y',\n   'name': 'Zhou, Y',\n   'lastname': 'Zhou'}],\n [{'forename': 'Steven H',\n   'affiliation': 'Department of Biology, Duke University, Durham, NC 27708, USA.',\n   'initials': 'SH',\n   'name': 'Spoel, SH',\n   'lastname': 'Spoel'},\n  {'forename': 'Zhonglin',\n   'initials': 'Z',\n   'name': 'Mou, Z',\n   'lastname': 'Mou'},\n  {'forename': 'Yasuomi',\n   'initials': 'Y',\n   'name': 'Tada, Y',\n   'lastname': 'Tada'},\n  {'forename': 'Natalie W',\n   'initials': 'NW',\n   'name': 'Spivey, NW',\n   'lastname': 'Spivey'},\n  {'forename': 'Pascal',\n   'initials': 'P',\n   'name': 'Genschik, P',\n   'lastname': 'Genschik'},\n  {'forename': 'Xinnian',\n   'initials': 'X',\n   'name': 'Dong, X',\n   'lastname': 'Dong'}]]"
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "list(df[(df['pmid'] == 29569306) | (df['pmid'] == 19490895)].authors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "       author      mesh  inst  email  country  forename  same_author  \\\n20637     0.0  0.176556  1.00    1.0      1.0       0.5            0   \n20682     0.0  0.004187  0.75    1.0      0.0       0.5            1   \n21222     0.0  0.000000  0.75    1.0      0.0       0.5            1   \n\n       same_name             pmid_both  \n20637          0  [30203285, 29569306]  \n20682          1  [30203285, 19490895]  \n21222          1  [29569306, 19490895]  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>mesh</th>\n      <th>inst</th>\n      <th>email</th>\n      <th>country</th>\n      <th>forename</th>\n      <th>same_author</th>\n      <th>same_name</th>\n      <th>pmid_both</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>20637</th>\n      <td>0.0</td>\n      <td>0.176556</td>\n      <td>1.00</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[30203285, 29569306]</td>\n    </tr>\n    <tr>\n      <th>20682</th>\n      <td>0.0</td>\n      <td>0.004187</td>\n      <td>0.75</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[30203285, 19490895]</td>\n    </tr>\n    <tr>\n      <th>21222</th>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.75</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[29569306, 19490895]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "### DEMO - REMOVE COUNTRY ###\n",
        "#df_core = df_core.drop(columns=\"country\",inplace=False)\n",
        "df_core[df_core['forename'] == .5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "There are 1184 pairs being used, half of them with the same author, 946 of them as train data\nBest Penalty: l2\nBest C: 1.0\n"
        }
      ],
      "source": [
        "X_train, y_train, X_test, y_test = lr_model_3.get_train_test(df_core,0.8,flag_da_case = True, da_samename_perc = 0.5)\n",
        "score, pred_prob, best_model = lr_model_3.log_model(X_train,y_train,X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "The score is:  0.5714285714285714\nThe features are:\nauthor, mesh, inst, email, country, forename\nThe weights are:  [-0.06  0.07  0.03 -0.05 -0.5  -0.23]\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"251.399844pt\" version=\"1.1\" viewBox=\"0 0 376.510403 251.399844\" width=\"376.510403pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 251.399844 \r\nL 376.510403 251.399844 \r\nL 376.510403 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 28.934062 224.64 \r\nL 363.734062 224.64 \r\nL 363.734062 7.2 \r\nL 28.934062 7.2 \r\nz\r\n\" style=\"fill:#eaeaf2;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <path clip-path=\"url(#pe506bca64e)\" d=\"M 49.210832 224.64 \r\nL 49.210832 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0.1 -->\r\n      <defs>\r\n       <path d=\"M 4.15625 35.296875 \r\nQ 4.15625 48 6.765625 55.734375 \r\nQ 9.375 63.484375 14.515625 67.671875 \r\nQ 19.671875 71.875 27.484375 71.875 \r\nQ 33.25 71.875 37.59375 69.546875 \r\nQ 41.9375 67.234375 44.765625 62.859375 \r\nQ 47.609375 58.5 49.21875 52.21875 \r\nQ 50.828125 45.953125 50.828125 35.296875 \r\nQ 50.828125 22.703125 48.234375 14.96875 \r\nQ 45.65625 7.234375 40.5 3 \r\nQ 35.359375 -1.21875 27.484375 -1.21875 \r\nQ 17.140625 -1.21875 11.234375 6.203125 \r\nQ 4.15625 15.140625 4.15625 35.296875 \r\nz\r\nM 13.1875 35.296875 \r\nQ 13.1875 17.671875 17.3125 11.828125 \r\nQ 21.4375 6 27.484375 6 \r\nQ 33.546875 6 37.671875 11.859375 \r\nQ 41.796875 17.71875 41.796875 35.296875 \r\nQ 41.796875 52.984375 37.671875 58.78125 \r\nQ 33.546875 64.59375 27.390625 64.59375 \r\nQ 21.34375 64.59375 17.71875 59.46875 \r\nQ 13.1875 52.9375 13.1875 35.296875 \r\nz\r\n\" id=\"ArialMT-48\"/>\r\n       <path d=\"M 9.078125 0 \r\nL 9.078125 10.015625 \r\nL 19.09375 10.015625 \r\nL 19.09375 0 \r\nz\r\n\" id=\"ArialMT-46\"/>\r\n       <path d=\"M 37.25 0 \r\nL 28.46875 0 \r\nL 28.46875 56 \r\nQ 25.296875 52.984375 20.140625 49.953125 \r\nQ 14.984375 46.921875 10.890625 45.40625 \r\nL 10.890625 53.90625 \r\nQ 18.265625 57.375 23.78125 62.296875 \r\nQ 29.296875 67.234375 31.59375 71.875 \r\nL 37.25 71.875 \r\nz\r\n\" id=\"ArialMT-49\"/>\r\n      </defs>\r\n      <g style=\"fill:#262626;\" transform=\"translate(41.565832 242.013594)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-48\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-49\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <path clip-path=\"url(#pe506bca64e)\" d=\"M 101.286594 224.64 \r\nL 101.286594 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 0.2 -->\r\n      <defs>\r\n       <path d=\"M 50.34375 8.453125 \r\nL 50.34375 0 \r\nL 3.03125 0 \r\nQ 2.9375 3.171875 4.046875 6.109375 \r\nQ 5.859375 10.9375 9.828125 15.625 \r\nQ 13.8125 20.3125 21.34375 26.46875 \r\nQ 33.015625 36.03125 37.109375 41.625 \r\nQ 41.21875 47.21875 41.21875 52.203125 \r\nQ 41.21875 57.421875 37.46875 61 \r\nQ 33.734375 64.59375 27.734375 64.59375 \r\nQ 21.390625 64.59375 17.578125 60.78125 \r\nQ 13.765625 56.984375 13.71875 50.25 \r\nL 4.6875 51.171875 \r\nQ 5.609375 61.28125 11.65625 66.578125 \r\nQ 17.71875 71.875 27.9375 71.875 \r\nQ 38.234375 71.875 44.234375 66.15625 \r\nQ 50.25 60.453125 50.25 52 \r\nQ 50.25 47.703125 48.484375 43.546875 \r\nQ 46.734375 39.40625 42.65625 34.8125 \r\nQ 38.578125 30.21875 29.109375 22.21875 \r\nQ 21.1875 15.578125 18.9375 13.203125 \r\nQ 16.703125 10.84375 15.234375 8.453125 \r\nz\r\n\" id=\"ArialMT-50\"/>\r\n      </defs>\r\n      <g style=\"fill:#262626;\" transform=\"translate(93.641594 242.013594)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-48\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <path clip-path=\"url(#pe506bca64e)\" d=\"M 153.362356 224.64 \r\nL 153.362356 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 0.3 -->\r\n      <defs>\r\n       <path d=\"M 4.203125 18.890625 \r\nL 12.984375 20.0625 \r\nQ 14.5 12.59375 18.140625 9.296875 \r\nQ 21.78125 6 27 6 \r\nQ 33.203125 6 37.46875 10.296875 \r\nQ 41.75 14.59375 41.75 20.953125 \r\nQ 41.75 27 37.796875 30.921875 \r\nQ 33.84375 34.859375 27.734375 34.859375 \r\nQ 25.25 34.859375 21.53125 33.890625 \r\nL 22.515625 41.609375 \r\nQ 23.390625 41.5 23.921875 41.5 \r\nQ 29.546875 41.5 34.03125 44.421875 \r\nQ 38.53125 47.359375 38.53125 53.46875 \r\nQ 38.53125 58.296875 35.25 61.46875 \r\nQ 31.984375 64.65625 26.8125 64.65625 \r\nQ 21.6875 64.65625 18.265625 61.421875 \r\nQ 14.84375 58.203125 13.875 51.765625 \r\nL 5.078125 53.328125 \r\nQ 6.6875 62.15625 12.390625 67.015625 \r\nQ 18.109375 71.875 26.609375 71.875 \r\nQ 32.46875 71.875 37.390625 69.359375 \r\nQ 42.328125 66.84375 44.9375 62.5 \r\nQ 47.5625 58.15625 47.5625 53.265625 \r\nQ 47.5625 48.640625 45.0625 44.828125 \r\nQ 42.578125 41.015625 37.703125 38.765625 \r\nQ 44.046875 37.3125 47.5625 32.6875 \r\nQ 51.078125 28.078125 51.078125 21.140625 \r\nQ 51.078125 11.765625 44.234375 5.25 \r\nQ 37.40625 -1.265625 26.953125 -1.265625 \r\nQ 17.53125 -1.265625 11.296875 4.34375 \r\nQ 5.078125 9.96875 4.203125 18.890625 \r\nz\r\n\" id=\"ArialMT-51\"/>\r\n      </defs>\r\n      <g style=\"fill:#262626;\" transform=\"translate(145.717356 242.013594)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-48\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-51\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <path clip-path=\"url(#pe506bca64e)\" d=\"M 205.438117 224.64 \r\nL 205.438117 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 0.4 -->\r\n      <defs>\r\n       <path d=\"M 32.328125 0 \r\nL 32.328125 17.140625 \r\nL 1.265625 17.140625 \r\nL 1.265625 25.203125 \r\nL 33.9375 71.578125 \r\nL 41.109375 71.578125 \r\nL 41.109375 25.203125 \r\nL 50.78125 25.203125 \r\nL 50.78125 17.140625 \r\nL 41.109375 17.140625 \r\nL 41.109375 0 \r\nz\r\nM 32.328125 25.203125 \r\nL 32.328125 57.46875 \r\nL 9.90625 25.203125 \r\nz\r\n\" id=\"ArialMT-52\"/>\r\n      </defs>\r\n      <g style=\"fill:#262626;\" transform=\"translate(197.793117 242.013594)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-48\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <path clip-path=\"url(#pe506bca64e)\" d=\"M 257.513879 224.64 \r\nL 257.513879 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 0.5 -->\r\n      <defs>\r\n       <path d=\"M 4.15625 18.75 \r\nL 13.375 19.53125 \r\nQ 14.40625 12.796875 18.140625 9.390625 \r\nQ 21.875 6 27.15625 6 \r\nQ 33.5 6 37.890625 10.78125 \r\nQ 42.28125 15.578125 42.28125 23.484375 \r\nQ 42.28125 31 38.0625 35.34375 \r\nQ 33.84375 39.703125 27 39.703125 \r\nQ 22.75 39.703125 19.328125 37.765625 \r\nQ 15.921875 35.84375 13.96875 32.765625 \r\nL 5.71875 33.84375 \r\nL 12.640625 70.609375 \r\nL 48.25 70.609375 \r\nL 48.25 62.203125 \r\nL 19.671875 62.203125 \r\nL 15.828125 42.96875 \r\nQ 22.265625 47.46875 29.34375 47.46875 \r\nQ 38.71875 47.46875 45.15625 40.96875 \r\nQ 51.609375 34.46875 51.609375 24.265625 \r\nQ 51.609375 14.546875 45.953125 7.46875 \r\nQ 39.0625 -1.21875 27.15625 -1.21875 \r\nQ 17.390625 -1.21875 11.203125 4.25 \r\nQ 5.03125 9.71875 4.15625 18.75 \r\nz\r\n\" id=\"ArialMT-53\"/>\r\n      </defs>\r\n      <g style=\"fill:#262626;\" transform=\"translate(249.868879 242.013594)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-48\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <path clip-path=\"url(#pe506bca64e)\" d=\"M 309.589641 224.64 \r\nL 309.589641 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 0.6 -->\r\n      <defs>\r\n       <path d=\"M 49.75 54.046875 \r\nL 41.015625 53.375 \r\nQ 39.84375 58.546875 37.703125 60.890625 \r\nQ 34.125 64.65625 28.90625 64.65625 \r\nQ 24.703125 64.65625 21.53125 62.3125 \r\nQ 17.390625 59.28125 14.984375 53.46875 \r\nQ 12.59375 47.65625 12.5 36.921875 \r\nQ 15.671875 41.75 20.265625 44.09375 \r\nQ 24.859375 46.4375 29.890625 46.4375 \r\nQ 38.671875 46.4375 44.84375 39.96875 \r\nQ 51.03125 33.5 51.03125 23.25 \r\nQ 51.03125 16.5 48.125 10.71875 \r\nQ 45.21875 4.9375 40.140625 1.859375 \r\nQ 35.0625 -1.21875 28.609375 -1.21875 \r\nQ 17.625 -1.21875 10.6875 6.859375 \r\nQ 3.765625 14.9375 3.765625 33.5 \r\nQ 3.765625 54.25 11.421875 63.671875 \r\nQ 18.109375 71.875 29.4375 71.875 \r\nQ 37.890625 71.875 43.28125 67.140625 \r\nQ 48.6875 62.40625 49.75 54.046875 \r\nz\r\nM 13.875 23.1875 \r\nQ 13.875 18.65625 15.796875 14.5 \r\nQ 17.71875 10.359375 21.1875 8.171875 \r\nQ 24.65625 6 28.46875 6 \r\nQ 34.03125 6 38.03125 10.484375 \r\nQ 42.046875 14.984375 42.046875 22.703125 \r\nQ 42.046875 30.125 38.078125 34.390625 \r\nQ 34.125 38.671875 28.125 38.671875 \r\nQ 22.171875 38.671875 18.015625 34.390625 \r\nQ 13.875 30.125 13.875 23.1875 \r\nz\r\n\" id=\"ArialMT-54\"/>\r\n      </defs>\r\n      <g style=\"fill:#262626;\" transform=\"translate(301.944641 242.013594)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-48\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <path clip-path=\"url(#pe506bca64e)\" d=\"M 361.665403 224.64 \r\nL 361.665403 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0.7 -->\r\n      <defs>\r\n       <path d=\"M 4.734375 62.203125 \r\nL 4.734375 70.65625 \r\nL 51.078125 70.65625 \r\nL 51.078125 63.8125 \r\nQ 44.234375 56.546875 37.515625 44.484375 \r\nQ 30.8125 32.421875 27.15625 19.671875 \r\nQ 24.515625 10.6875 23.78125 0 \r\nL 14.75 0 \r\nQ 14.890625 8.453125 18.0625 20.40625 \r\nQ 21.234375 32.375 27.171875 43.484375 \r\nQ 33.109375 54.59375 39.796875 62.203125 \r\nz\r\n\" id=\"ArialMT-55\"/>\r\n      </defs>\r\n      <g style=\"fill:#262626;\" transform=\"translate(354.020403 242.013594)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-48\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-55\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_8\">\r\n      <path clip-path=\"url(#pe506bca64e)\" d=\"M 28.934062 224.64 \r\nL 363.734062 224.64 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(13.317031 228.576797)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_9\">\r\n      <path clip-path=\"url(#pe506bca64e)\" d=\"M 28.934062 192.282857 \r\nL 363.734062 192.282857 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 10 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 196.219654)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-49\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_10\">\r\n      <path clip-path=\"url(#pe506bca64e)\" d=\"M 28.934062 159.925714 \r\nL 363.734062 159.925714 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 20 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 163.862511)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-50\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_11\">\r\n      <path clip-path=\"url(#pe506bca64e)\" d=\"M 28.934062 127.568571 \r\nL 363.734062 127.568571 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 30 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 131.505368)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-51\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_12\">\r\n      <path clip-path=\"url(#pe506bca64e)\" d=\"M 28.934062 95.211429 \r\nL 363.734062 95.211429 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 40 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 99.148225)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-52\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_13\">\r\n      <path clip-path=\"url(#pe506bca64e)\" d=\"M 28.934062 62.854286 \r\nL 363.734062 62.854286 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 50 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 66.791083)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-53\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_14\">\r\n      <path clip-path=\"url(#pe506bca64e)\" d=\"M 28.934062 30.497143 \r\nL 363.734062 30.497143 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 60 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 34.43394)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-54\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 44.152244 224.64 \r\nL 54.297699 224.64 \r\nL 54.297699 221.404286 \r\nL 44.152244 221.404286 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 54.297699 224.64 \r\nL 64.443153 224.64 \r\nL 64.443153 208.461429 \r\nL 54.297699 208.461429 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 64.443153 224.64 \r\nL 74.588608 224.64 \r\nL 74.588608 172.868571 \r\nL 64.443153 172.868571 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 74.588608 224.64 \r\nL 84.734063 224.64 \r\nL 84.734063 153.454286 \r\nL 74.588608 153.454286 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_7\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 84.734063 224.64 \r\nL 94.879517 224.64 \r\nL 94.879517 214.932857 \r\nL 84.734063 214.932857 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_8\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 94.879517 224.64 \r\nL 105.024972 224.64 \r\nL 105.024972 218.168571 \r\nL 94.879517 218.168571 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_9\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 105.024972 224.64 \r\nL 115.170426 224.64 \r\nL 115.170426 224.64 \r\nL 105.024972 224.64 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_10\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 115.170426 224.64 \r\nL 125.315881 224.64 \r\nL 125.315881 224.64 \r\nL 115.170426 224.64 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_11\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 125.315881 224.64 \r\nL 135.461335 224.64 \r\nL 135.461335 224.64 \r\nL 125.315881 224.64 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_12\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 135.461335 224.64 \r\nL 145.60679 224.64 \r\nL 145.60679 208.461429 \r\nL 135.461335 208.461429 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_13\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 145.60679 224.64 \r\nL 155.752244 224.64 \r\nL 155.752244 221.404286 \r\nL 145.60679 221.404286 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_14\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 155.752244 224.64 \r\nL 165.897699 224.64 \r\nL 165.897699 218.168571 \r\nL 155.752244 218.168571 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_15\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 165.897699 224.64 \r\nL 176.043153 224.64 \r\nL 176.043153 224.64 \r\nL 165.897699 224.64 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_16\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 176.043153 224.64 \r\nL 186.188608 224.64 \r\nL 186.188608 224.64 \r\nL 176.043153 224.64 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_17\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 186.188608 224.64 \r\nL 196.334063 224.64 \r\nL 196.334063 224.64 \r\nL 186.188608 224.64 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_18\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 196.334063 224.64 \r\nL 206.479517 224.64 \r\nL 206.479517 224.64 \r\nL 196.334063 224.64 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_19\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 206.479517 224.64 \r\nL 216.624972 224.64 \r\nL 216.624972 224.64 \r\nL 206.479517 224.64 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_20\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 216.624972 224.64 \r\nL 226.770426 224.64 \r\nL 226.770426 221.404286 \r\nL 216.624972 221.404286 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_21\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 226.770426 224.64 \r\nL 236.915881 224.64 \r\nL 236.915881 221.404286 \r\nL 226.770426 221.404286 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_22\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 236.915881 224.64 \r\nL 247.061335 224.64 \r\nL 247.061335 224.64 \r\nL 236.915881 224.64 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_23\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 247.061335 224.64 \r\nL 257.20679 224.64 \r\nL 257.20679 224.64 \r\nL 247.061335 224.64 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_24\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 257.20679 224.64 \r\nL 267.352244 224.64 \r\nL 267.352244 224.64 \r\nL 257.20679 224.64 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_25\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 267.352244 224.64 \r\nL 277.497699 224.64 \r\nL 277.497699 224.64 \r\nL 267.352244 224.64 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_26\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 277.497699 224.64 \r\nL 287.643153 224.64 \r\nL 287.643153 224.64 \r\nL 277.497699 224.64 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_27\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 287.643153 224.64 \r\nL 297.788608 224.64 \r\nL 297.788608 224.64 \r\nL 287.643153 224.64 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_28\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 297.788608 224.64 \r\nL 307.934063 224.64 \r\nL 307.934063 224.64 \r\nL 297.788608 224.64 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_29\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 307.934063 224.64 \r\nL 318.079517 224.64 \r\nL 318.079517 224.64 \r\nL 307.934063 224.64 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_30\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 318.079517 224.64 \r\nL 328.224972 224.64 \r\nL 328.224972 17.554286 \r\nL 318.079517 17.554286 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_31\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 328.224972 224.64 \r\nL 338.370426 224.64 \r\nL 338.370426 33.732857 \r\nL 328.224972 33.732857 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_32\">\r\n    <path clip-path=\"url(#pe506bca64e)\" d=\"M 338.370426 224.64 \r\nL 348.515881 224.64 \r\nL 348.515881 43.44 \r\nL 338.370426 43.44 \r\nz\r\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_33\">\r\n    <path d=\"M 28.934062 224.64 \r\nL 28.934062 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_34\">\r\n    <path d=\"M 363.734062 224.64 \r\nL 363.734062 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_35\">\r\n    <path d=\"M 28.934063 224.64 \r\nL 363.734062 224.64 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_36\">\r\n    <path d=\"M 28.934063 7.2 \r\nL 363.734062 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pe506bca64e\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"28.934062\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD7CAYAAABgzo9kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAUuElEQVR4nO3df2xV9f3H8dcdLT+KJWo5V8zSNJka3MxA5jatutZurJS2l2rtFsCICWNSnSU0C47URhadkYGm2+JqZNlcNC4GXTtKw67g2JqRMpkus4GxzUxacWB7uYBt+VHa3s/+MN/7lWz0nHN7f/Xj85GYcO4995zX+/by8nJ6z7kBY4wRAMA6n8p0AABAalDwAGApCh4ALEXBA4ClKHgAsBQFDwCWouABwFI5mdrxqVNnFIsl5yP4BQWXKRodTsq2soFt80j2zcQ82c3GeU6dOqMrrpjt63EZK/hYzCSt4P9vezaxbR7JvpmYJ7sxD4doAMBaFDwAWIqCBwBLUfAAYCkKHgAsRcEDgKUoeACwVMY+Bw8AmZI/Z5ZmznCvv/MjYxoaPJeGRKlBwQP4xJk5I0eh7+5wXW/n0zUaSkOeVOEQDQBYioIHAEtR8ABgKQoeACxFwQOApSh4ALAUBQ8AlvJU8Hv37lVtba2WLl2qH/zgB5Kk7u5uhUIhlZeXq6WlJaUhAQD+uRb80aNHtWnTJrW2tqqjo0N/+9vf1NXVpaamJrW2tmrXrl06ePCgurq60pEXAOCRa8Hv2bNHlZWVmjdvnnJzc9XS0qJZs2apqKhIhYWFysnJUSgUUjgcTkdeAIBHrpcq6OvrU25ururr63X8+HHdcccduu666+Q4TnydYDCo/v7+lAYFAPjjWvDj4+N688039eKLLyovL08PPPCAZs6cqUAgEF/HGHPRshcFBZf5TzsBx8lP6vYyzbZ5JPtmYp7slqx5suV5SaQzXQt+7ty5Ki4u1pVXXilJWrx4scLhsKZNmxZfJxKJKBgM+tpxNDqctG89d5x8RSJT+ZJAF7NtHsm+mZgnu7nN46e0s+F5cZx8RaPDvkve9Rh8WVmZ9u3bp8HBQY2Pj+uPf/yjKioqdOTIEfX19Wl8fFydnZ0qKSlJODwAIPlc38EvXLhQa9as0cqVKzU6OqrbbrtNK1as0Gc+8xk1NDRoZGREpaWlqqioSEdeAEibC6Pjnt/tZ+O14z1dD76urk51dXUX3VZcXKyOjo6UhAKAbDA9d5qn68ZL2XnteM5kBQBLUfAAYCkKHgAsRcEDgKUoeACwFAUPAJai4AHAUhQ8AFjK04lOAICJeT3rNZ1nvFLwAJAEXs96TecZrxyiAQBLUfAAYCkKHgAsRcEDgKUoeACwFAUPAJai4AHAUhQ8AFiKggcAS1HwAGApCh4ALEXBA4ClKHgAsBQFDwCW8nS54HvvvVcnT55UTs5Hqz/22GN677339Oyzz2psbEz33Xef7rnnnpQGBQD441rwxhj19vbq97//fbzg+/v71djYqLa2Nk2fPl3Lly/XzTffrGuvvTblgQEA3rgW/LvvvitJWr16tU6fPq1vfvObmj17tm655RZdfvnlkqQlS5YoHA7roYceSm1aAIBnrsfgBwcHVVxcrJ/+9Kf65S9/qZdfflnHjh2T4zjxdYLBoPr7+1MaFADgj+s7+EWLFmnRokXx5bq6Oj355JN64IEH4rcZYxQIBHztuKDgMl/ru/HyXYhTiW3zSPbNxDzZLZvnSSRbIp3pWvBvvvmmRkdHVVxcLOmjMv/0pz+tSCQSXycSiSgYDPracTQ6rFjM+Iz7vzlOviKRdH3LYerZNo9k30zMk93c5sl0+ft9rh0nX9HosO+Sdz1EMzQ0pC1btmhkZETDw8Nqb2/X1q1btX//fp08eVLnzp3T7t27VVJS4mvHAIDUcn0HX1ZWprffflt33nmnYrGYVq5cqZtuukmNjY1atWqVRkdHVVdXpwULFqQjLwDAI0+fg1+/fr3Wr19/0W2hUEihUCgloQAAk8eZrABgKQoeACxFwQOApSh4ALAUBQ8AlqLgAcBSFDwAWIqCBwBLUfAAYCkKHgAsRcEDgKUoeACwFAUPAJai4AHAUhQ8AFiKggcAS1HwAGApCh4ALEXBA4ClKHgAsBQFDwCWouABwFIUPABYynPB//CHP9TGjRslSYcPH1Ztba2WLFmiRx55RGNjYykLCABIjKeC379/v9rb2+PLGzZs0KOPPqrXXntNxhht3749ZQEBAIlxLfjTp0+rpaVF9fX1kqR///vfOn/+vG688UZJUm1trcLhcGpTAgB8cy34Rx99VI2NjZozZ44kaWBgQI7jxO93HEf9/f2pSwgASEjORHe+8soruvrqq1VcXKy2tjZJUiwWUyAQiK9jjLlo2auCgst8P2YijpOf1O1lmm3zSPbNxDzZLZvnSSRbIp05YcHv2rVLkUhENTU1+vDDD3X27FkFAgFFIpH4OidOnFAwGPS942h0WLGY8f24/8Vx8hWJDCVlW9nAtnkk+2ZinuzmNk+my9/vc+04+YpGh32X/IQF//zzz8f/3NbWpgMHDujJJ59UdXW13nrrLd10003asWOHSkpKfO0UAJB6Exb8pTz11FNqbm7W8PCwbrjhBq1atSrZuQAAk+S54Gtra1VbWytJuv766/Xqq6+mLBQAYPI4kxUALEXBA4ClKHgAsBQFDwCWouABwFIUPABYioIHAEtR8ABgKQoeACxFwQOApSh4ALAUBQ8AlqLgAcBSFDwAWIqCBwBLUfAAYCkKHgAsRcEDgKUoeACwFAUPAJai4AHAUhQ8AFiKggcAS1HwAGApTwX/4x//WJWVlaqqqtLzzz8vSeru7lYoFFJ5eblaWlpSGhIA4F+O2woHDhzQn/70J3V0dGhsbEyVlZUqLi5WU1OTXnzxRV199dVau3aturq6VFpamo7MAAAPXN/Bf/nLX9YLL7ygnJwcRaNRjY+Pa3BwUEVFRSosLFROTo5CoZDC4XA68gIAPHJ9By9Jubm5+slPfqJf/OIXqqio0MDAgBzHid8fDAbV39/va8cFBZf5S+rCcfKTur1Ms20eyb6ZmCe7ZfM8iWRLpDM9FbwkrVu3Tt/+9rdVX1+v3t5eBQKB+H3GmIuWvYhGhxWLGV+PuRTHyVckMpSUbWUD2+aR7JuJebKb2zyZLn+/z7Xj5CsaHfZd8q6HaP71r3/p8OHDkqRZs2apvLxcb7zxhiKRyMfCRhQMBn3tGACQWq4F//7776u5uVkXLlzQhQsX9Lvf/U7Lly/XkSNH1NfXp/HxcXV2dqqkpCQdeQEAHrkeoiktLVVPT4/uvPNOTZs2TeXl5aqqqtKVV16phoYGjYyMqLS0VBUVFenICwDwyNMx+IaGBjU0NFx0W3FxsTo6OlISCgAweZzJCgCWouABwFIUPABYioIHAEtR8ABgKQoeACxFwQOApSh4ALAUBQ8AlqLgAcBSFDwAWIqCBwBLUfAAYCkKHgAsRcEDgKUoeACwFAUPAJai4AHAUhQ8AFiKggcAS3n60m18JH/OLM2c4f6UnR8Z09DguTQkAoBLo+B9mDkjR6Hv7nBdb+fTNRpKQx4AmAiHaADAUp4K/plnnlFVVZWqqqq0ZcsWSVJ3d7dCoZDKy8vV0tKS0pAAAP9cC767u1v79u1Te3u7fvOb3+jQoUPq7OxUU1OTWltbtWvXLh08eFBdXV3pyAsA8Mi14B3H0caNGzV9+nTl5ubqmmuuUW9vr4qKilRYWKicnByFQiGFw+F05AUAeORa8Nddd51uvPFGSVJvb69++9vfKhAIyHGc+DrBYFD9/f2pSwkA8M3zp2jeeecdrV27Vg8//LCmTZum3t7e+H3GGAUCAV87Lii4zNf6bhwnP6nbm6zJ5sm2eZLBtpmYJ7tl8zyJZEukMz0V/FtvvaV169apqalJVVVVOnDggCKRSPz+SCSiYDDoa8fR6LBiMeMv7SU4Tr4ikdR/MNHPD2UyedI1TzrZNhPzZDe3eTJd/n6fa8fJVzQ67LvkXQ/RHD9+XN/5znf01FNPqaqqSpK0cOFCHTlyRH19fRofH1dnZ6dKSkp87RgAkFqu7+B//vOfa2RkRJs3b47ftnz5cm3evFkNDQ0aGRlRaWmpKioqUhoUAOCPa8E3Nzerubn5f97X0dGR9EAAgOTgTFYAsBQFDwCWouABwFIUPABYioIHAEtR8ABgKQoeACxFwQOApfjKPnn/rlUAmEpoNfn7rlUAmCo4RAMAlqLgAcBSFDwAWIqCBwBLUfAAYCkKHgAsRcEDgKUoeACwFAUPAJai4AHAUhQ8AFiKggcAS1HwAGApzwU/PDys6upqvf/++5Kk7u5uhUIhlZeXq6WlJWUBAQCJ8VTwb7/9tlasWKHe3l5J0vnz59XU1KTW1lbt2rVLBw8eVFdXVypzAgB88lTw27dv16ZNmxQMBiVJPT09KioqUmFhoXJychQKhRQOh1MaFADgj6cv/HjiiScuWh4YGJDjOPHlYDCo/v7+5CYDAExKQt/oFIvFFAgE4svGmIuWvSgouCyRXV+S4+QndXuTNdk82TZPMtg2E/Nkt2yeJ5FsiXRmQgU/b948RSKR+HIkEokfvvEqGh1WLGYS2f1/cZx8RSJDk3p8sk02z2Qen41sm4l5spvbPJkuf7/PtePkKxod9l3yCX1McuHChTpy5Ij6+vo0Pj6uzs5OlZSUJLIpAECKJPQOfsaMGdq8ebMaGho0MjKi0tJSVVRUJDsbAGASfBX83r17438uLi5WR0dH0gMBAJKDM1kBwFIUPABYioIHAEtR8ABgKQoeACxFwQOApSh4ALAUBQ8AlqLgAcBSFDwAWIqCBwBLJXSxsakgf84szZxh7Xhp4/V5PD8ypqHBc2lIBMAraxtw5owchb67w9O6O5+uSXGaqcvr87jz6RrZczVxwA4cogEAS1HwAGApCh4ALEXBA4ClKHgAsJS1n6LJpAuj456+tZ2PFgJIJQo+BabnTuOjhQAyjkM0AGAp3sFn0ESHcj5+u02HcjgzFkgfCj6DPomHcjgzFkgfDtEAgKUm9Q5+586devbZZzU2Nqb77rtP99xzT7JyXdKl/onv5VMrSB0vnxz6pP6MvB6WGrkwrhnTp7mux+EreJVwwff396ulpUVtbW2aPn26li9frptvvlnXXnttMvP9Fz//xEf6+Dnc9Enj5zXL4SskU8IF393drVtuuUWXX365JGnJkiUKh8N66KGHPD3+U58KJLprBa+YldT1UrHNZK83medrsj6JM3vhJ99UeG6y/fn2y22eTPZIIs91Io8JGGOM70dJeu6553T27Fk1NjZKkl555RX19PTo8ccfT2RzAIAkS/iXrLFYTIHA//8fxRhz0TIAILMSLvh58+YpEonElyORiILBYFJCAQAmL+GCv/XWW7V//36dPHlS586d0+7du1VSUpLMbACASUj4l6xXXXWVGhsbtWrVKo2Ojqqurk4LFixIZjYAwCQk/EtWAEB240xWALAUBQ8AlqLgAcBSFDwAWGpKFfzOnTtVWVmp8vJyvfTSS5dc7+GHH1ZbW1sakyXGbZ7XX39dNTU1WrZsmR588EF9+OGHGUjpnds8e/bsUSgUUlVVlTZu3KgLFy5kIKV3Xl9vf/jDH/TVr341jckS5zbTM888o7KyMtXU1KimpmbCubOB2zzvvvuu7r33Xi1btkzf+ta3pvTfocOHD8d/LjU1NfrKV76i6urqiTdopogPPvjAlJWVmVOnTpkzZ86YUChk3nnnnf9aZ+3atWbBggXm17/+dYaSeuM2z9DQkLntttvMBx98YIwx5kc/+pF5/PHHMxXXlds8Z86cMbfffruJRCLGGGPWr19vXn755UzFdeXl9WaMMZFIxFRUVJiysrIMpPTHy0xr1641f/nLXzKU0B+3eWKxmCkvLzddXV3GGGO2bt1qtmzZkqm4rry+5owx5uzZs6aqqsr8+c9/nnCbU+Yd/McvbpaXlxe/uNnH7dy5U1/72te0dOnSDKX0zm2e0dFRbdq0SVdddZUkaf78+Tp+/Him4rpymycvL0979+7V3Llzde7cOUWjUc2ZMyeDiSfm5fUmSc3NzZ4vsJdpXmY6ePCgnnvuOYVCIT322GMaGRnJUFp3bvMcOnRIeXl58RMw6+vr03JJ80R5fc1JH10L7Etf+pK++MUvTrjNKVPwAwMDchwnvhwMBtXf33/ROmvWrNE3vvGNdEdLiNs8V1xxhb7+9a9Lks6fP69t27Zp8eLFac/plZefT25urrq6unTHHXfo1KlTuv3229Md0zMv87zwwgv63Oc+p4ULF6Y7XkLcZjpz5ow++9nPasOGDWpvb9fg4KBaW1szEdUTt3nee+89zZ07V01NTbrrrru0adMm5eXlZSKqJ15ec5I0NDSk7du3e3pjMWUK3raLm3mdZ2hoSPfff7+uv/563XXXXemM6IvXeUpLS/XGG2+orKxM3//+99OY0B+3ef75z39q9+7devDBBzMRLyFuM82ePVs/+9nPdM011ygnJ0erV69WV1dXJqJ64jbP2NiYDhw4oBUrVqi9vV2FhYXavHlzJqJ64vXvUEdHhxYvXqyCggLXbU6Zgrft4mZe5hkYGNDKlSs1f/58PfHEE+mO6IvbPKdPn9a+ffviy6FQSP/4xz/SmtEPt3nC4bAikYjuvvtu3X///fGfVTZzm+nYsWN69dVX48vGGOXkZO/XNrvN4ziOioqK9PnPf16SVF1drZ6enrTn9Mprx73++uuqrKz0tM0pU/C2XdzMbZ7x8XHV19dr6dKleuSRR7L+Xytu8xhjtGHDBh07dkzSRwX5hS98IVNxXbnNs27dOr322mvasWOHtm3bpmAwqF/96lcZTOzObaaZM2dq69atOnr0qIwxeumll+KHCbOR2zyLFi3SyZMn9fe//12StHfvXt1www2ZiuvKS8cZY3To0CEtWrTI20aT9ivgNOjo6DBVVVWmvLzcbNu2zRhjzJo1a0xPT89F633ve9/L+k/RGDPxPLt37zbz5883y5Yti//X1NSU4cQTc/v57Nmzx1RXV5tQKGQaGxvN4OBgJuO68vp6O3r06JT4FI0x7jOFw+H4/Rs3bjQjIyOZjOvKbZ6//vWv5u677zaVlZVm9erV5sSJE5mM68ptnhMnTphbb73V8/a42BgAWGrKHKIBAPhDwQOApSh4ALAUBQ8AlqLgAcBSFDwAWIqCBwBLUfAAYKn/AJxXmkoadMXxAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(\"The score is: \", score)\n",
        "print(\"The features are:\\nauthor, mesh, inst, email, country, forename\")\n",
        "print(\"The weights are: \", np.round(best_model.best_estimator_.coef_.reshape(-1),2))\n",
        "plt.hist(pred_prob,bins=30);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DBSCAN\n",
        "possible use_cases<br><br>\n",
        "<ul>\n",
        "3_ua_same - 3 Unique Authors with similar num papers<br>\n",
        "2_ua_dif - 2 Unique Authors with dif. num papers<br>\n",
        "2_da_same - 2 Disambiguated Authors with same num papers<br>\n",
        "2_da_dif -  2 Disambiguated Authors with dif num papers<br>\n",
        "</ul>\n",
        "                    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Processing combination number 1 from 50\nTotal number of papers:  37\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  1369\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  1369\n\n\nProcessing combination number 2 from 50\nTotal number of papers:  32\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  1024\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  1024\n\n\nProcessing combination number 3 from 50\nTotal number of papers:  21\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  441\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  441\n\n\nProcessing combination number 4 from 50\nTotal number of papers:  12\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  144\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  144\n\n\nProcessing combination number 5 from 50\nTotal number of papers:  33\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  1089\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  1089\n\n\nProcessing combination number 6 from 50\nTotal number of papers:  25\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  625\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  625\n\n\nProcessing combination number 7 from 50\nTotal number of papers:  29\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  841\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  841\n\n\nProcessing combination number 8 from 50\nTotal number of papers:  29\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  841\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  841\n\n\nProcessing combination number 9 from 50\nTotal number of papers:  16\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  256\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  256\n\n\nProcessing combination number 10 from 50\nTotal number of papers:  16\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  256\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  256\n\n\nProcessing combination number 11 from 50\nTotal number of papers:  28\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  784\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  784\n\n\nProcessing combination number 12 from 50\nTotal number of papers:  46\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  2116\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  2116\n\n\nProcessing combination number 13 from 50\nTotal number of papers:  47\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  2209\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  2209\n\n\nProcessing combination number 14 from 50\nTotal number of papers:  33\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  1089\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  1089\n\n\nProcessing combination number 15 from 50\nTotal number of papers:  45\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  2025\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  2025\n\n\nProcessing combination number 16 from 50\nTotal number of papers:  24\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  576\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  576\n\n\nProcessing combination number 17 from 50\nTotal number of papers:  37\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  1369\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  1369\n\n\nProcessing combination number 18 from 50\nTotal number of papers:  46\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  2116\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  2116\n\n\nProcessing combination number 19 from 50\nTotal number of papers:  30\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  900\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  900\n\n\nProcessing combination number 20 from 50\nTotal number of papers:  37\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  1369\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  1369\n\n\nProcessing combination number 21 from 50\nTotal number of papers:  33\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  1089\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  1089\n\n\nProcessing combination number 22 from 50\nTotal number of papers:  37\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  1369\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  1369\n\n\nProcessing combination number 23 from 50\nTotal number of papers:  39\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  1521\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  1521\n\n\nProcessing combination number 24 from 50\nTotal number of papers:  28\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  784\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  784\n\n\nProcessing combination number 25 from 50\nTotal number of papers:  41\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  1681\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  1681\n\n\nProcessing combination number 26 from 50\nTotal number of papers:  42\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  1764\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  1764\n\n\nProcessing combination number 27 from 50\nTotal number of papers:  29\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  841\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  841\n\n\nProcessing combination number 28 from 50\nTotal number of papers:  45\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  2025\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  2025\n\n\nProcessing combination number 29 from 50\nTotal number of papers:  54\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  2916\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  2916\n\n\nProcessing combination number 30 from 50\nTotal number of papers:  28\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  784\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  784\n\n\nProcessing combination number 31 from 50\nTotal number of papers:  34\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  1156\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  1156\n\n\nProcessing combination number 32 from 50\nTotal number of papers:  34\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  1156\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  1156\n\n\nProcessing combination number 33 from 50\nTotal number of papers:  41\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  1681\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  1681\n\n\nProcessing combination number 34 from 50\nTotal number of papers:  29\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  841\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  841\n\n\nProcessing combination number 35 from 50\nTotal number of papers:  28\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  784\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  784\n\n\nProcessing combination number 36 from 50\nTotal number of papers:  41\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  1681\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  1681\n\n\nProcessing combination number 37 from 50\nTotal number of papers:  24\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  576\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  576\n\n\nProcessing combination number 38 from 50\nTotal number of papers:  41\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  1681\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  1681\n\n\nProcessing combination number 39 from 50\nTotal number of papers:  17\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  289\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  289\n\n\nProcessing combination number 40 from 50\nTotal number of papers:  28\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  784\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  784\n\n\nProcessing combination number 41 from 50\nTotal number of papers:  41\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  1681\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  1681\n\n\nProcessing combination number 42 from 50\nTotal number of papers:  24\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  576\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  576\n\n\nProcessing combination number 43 from 50\nTotal number of papers:  32\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  1024\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  1024\n\n\nProcessing combination number 44 from 50\nTotal number of papers:  28\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  784\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  784\n\n\nProcessing combination number 45 from 50\nTotal number of papers:  43\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  1849\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  1849\n\n\nProcessing combination number 46 from 50\nTotal number of papers:  37\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  1369\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  1369\n\n\nProcessing combination number 47 from 50\nTotal number of papers:  38\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  1444\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  1444\n\n\nProcessing combination number 48 from 50\nTotal number of papers:  12\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  144\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  144\n\n\nProcessing combination number 49 from 50\nTotal number of papers:  33\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  1089\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  1089\n\n\nProcessing combination number 50 from 50\nTotal number of papers:  28\nBuilding Same Author/Name Columns\nNumber of paper combinations (pre-cleaning) is:  784\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  784\n\n\n"
        }
      ],
      "source": [
        "y_hat_comb = db_scan_3.db_multiple(ps,df,scaler = scaler, use_case=\"2_da_same\",num_cases = 50,model=best_model,epsilon=.47)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Situation 0\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.26378378378378375\nRecall:  0.5135135135135135\n              mis_integration  mis_separation\n1 cluster(s)              2.0             4.0\n2 cluster(s)              1.0             NaN\n\n-------------------\n\nSituation 1\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.28089285714285717\nRecall:  0.40625\n              mis_integration  mis_separation\n1 cluster(s)                1               2\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 2\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.2743764172335601\nRecall:  0.5238095238095238\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 3\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.25\nRecall:  0.5\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 4\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.22438672438672438\nRecall:  0.30303030303030304\n              mis_integration  mis_separation\n1 cluster(s)                1               2\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 5\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.2704\nRecall:  0.52\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 6\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.3463488843813387\nRecall:  0.5517241379310345\n              mis_integration  mis_separation\n1 cluster(s)                1               1\n2 cluster(s)                2               3\n\n-------------------\n\nSituation 7\nNum Clusters:  3\nNum Unique Authors:  4\nPrecision:  0.38066260987153483\nRecall:  0.4482758620689655\n              mis_integration  mis_separation\n2 cluster(s)                1               1\n3 cluster(s)                3               3\n\n-------------------\n\nSituation 8\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.6448412698412699\nRecall:  0.625\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 9\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.25\nRecall:  0.5\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 10\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.25\nRecall:  0.5\n              mis_integration  mis_separation\n1 cluster(s)              2.0             4.0\n2 cluster(s)              1.0             NaN\n\n-------------------\n\nSituation 11\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.126583850931677\nRecall:  0.2391304347826087\n              mis_integration  mis_separation\n2 cluster(s)                3               4\n\n-------------------\n\nSituation 12\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.20836390315480555\nRecall:  0.2765957446808511\n              mis_integration  mis_separation\n1 cluster(s)                1               2\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 13\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.19061942959001785\nRecall:  0.36363636363636365\n              mis_integration  mis_separation\n2 cluster(s)                3               4\n\n-------------------\n\nSituation 14\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.18903256704980842\nRecall:  0.3111111111111111\n              mis_integration  mis_separation\n2 cluster(s)                3               4\n\n-------------------\n\nSituation 15\nNum Clusters:  3\nNum Unique Authors:  4\nPrecision:  0.375\nRecall:  0.5\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 16\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.15250965250965248\nRecall:  0.2702702702702703\n              mis_integration  mis_separation\n2 cluster(s)                3               4\n\n-------------------\n\nSituation 17\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.18643619366787195\nRecall:  0.30434782608695654\n              mis_integration  mis_separation\n2 cluster(s)                3               4\n\n-------------------\n\nSituation 18\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.23148148148148148\nRecall:  0.43333333333333335\n              mis_integration  mis_separation\n1 cluster(s)              NaN             1.0\n2 cluster(s)              3.0             3.0\n\n-------------------\n\nSituation 19\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.15250965250965248\nRecall:  0.2702702702702703\n              mis_integration  mis_separation\n2 cluster(s)                3               4\n\n-------------------\n\nSituation 20\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.2496392496392496\nRecall:  0.48484848484848486\n              mis_integration  mis_separation\n1 cluster(s)                1               2\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 21\nNum Clusters:  3\nNum Unique Authors:  4\nPrecision:  0.36972972972972973\nRecall:  0.40540540540540543\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n3 cluster(s)                2               2\n\n-------------------\n\nSituation 22\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.16524216524216526\nRecall:  0.3076923076923077\n              mis_integration  mis_separation\n2 cluster(s)                3               4\n\n-------------------\n\nSituation 23\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.1488095238095238\nRecall:  0.2857142857142857\n              mis_integration  mis_separation\n2 cluster(s)                3               4\n\n-------------------\n\nSituation 24\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.1873170731707317\nRecall:  0.3170731707317073\n              mis_integration  mis_separation\n2 cluster(s)                3               4\n\n-------------------\n\nSituation 25\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.1830812324929972\nRecall:  0.30952380952380953\n              mis_integration  mis_separation\n1 cluster(s)              NaN             1.0\n2 cluster(s)              3.0             3.0\n\n-------------------\n\nSituation 26\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.30439952437574314\nRecall:  0.5517241379310345\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 27\nNum Clusters:  3\nNum Unique Authors:  4\nPrecision:  0.3466034178677857\nRecall:  0.4444444444444444\n              mis_integration  mis_separation\n2 cluster(s)                1               1\n3 cluster(s)                3               3\n\n-------------------\n\nSituation 28\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.1517241379310345\nRecall:  0.25925925925925924\n              mis_integration  mis_separation\n2 cluster(s)                3               4\n\n-------------------\n\nSituation 29\nNum Clusters:  3\nNum Unique Authors:  4\nPrecision:  0.4399092970521542\nRecall:  0.5\n              mis_integration  mis_separation\n2 cluster(s)                3               3\n3 cluster(s)                1               1\n\n-------------------\n\nSituation 30\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.14419934640522875\nRecall:  0.2647058823529412\n              mis_integration  mis_separation\n2 cluster(s)                3               4\n\n-------------------\n\nSituation 31\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.27622159975101157\nRecall:  0.38235294117647056\n              mis_integration  mis_separation\n1 cluster(s)                1               2\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 32\nNum Clusters:  3\nNum Unique Authors:  4\nPrecision:  0.42085946573751454\nRecall:  0.43902439024390244\n              mis_integration  mis_separation\n1 cluster(s)                1               1\n2 cluster(s)                1               1\n3 cluster(s)                2               2\n\n-------------------\n\nSituation 33\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.17849898580121704\nRecall:  0.3448275862068966\n              mis_integration  mis_separation\n1 cluster(s)              NaN             1.0\n2 cluster(s)              3.0             3.0\n\n-------------------\n\nSituation 34\nNum Clusters:  3\nNum Unique Authors:  4\nPrecision:  0.35714285714285715\nRecall:  0.39285714285714285\n              mis_integration  mis_separation\n1 cluster(s)                1               1\n2 cluster(s)                1               1\n3 cluster(s)                2               2\n\n-------------------\n\nSituation 35\nNum Clusters:  3\nNum Unique Authors:  4\nPrecision:  0.3931875525651808\nRecall:  0.43902439024390244\n              mis_integration  mis_separation\n1 cluster(s)                1               1\n2 cluster(s)                1               1\n3 cluster(s)                2               2\n\n-------------------\n\nSituation 36\nNum Clusters:  3\nNum Unique Authors:  4\nPrecision:  0.25\nRecall:  0.2916666666666667\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n3 cluster(s)                2               2\n\n-------------------\n\nSituation 37\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.28847771236333053\nRecall:  0.5365853658536586\n              mis_integration  mis_separation\n1 cluster(s)              2.0             4.0\n2 cluster(s)              1.0             NaN\n\n-------------------\n\nSituation 38\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.28027681660899656\nRecall:  0.5294117647058824\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 39\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.16666666666666666\nRecall:  0.2857142857142857\n              mis_integration  mis_separation\n2 cluster(s)                3               4\n\n-------------------\n\nSituation 40\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.1704878048780488\nRecall:  0.3170731707317073\n              mis_integration  mis_separation\n2 cluster(s)                3               4\n\n-------------------\n\nSituation 41\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.25\nRecall:  0.5\n              mis_integration  mis_separation\n1 cluster(s)              2.0             4.0\n2 cluster(s)              1.0             NaN\n\n-------------------\n\nSituation 42\nNum Clusters:  3\nNum Unique Authors:  4\nPrecision:  0.35887896825396826\nRecall:  0.375\n              mis_integration  mis_separation\n2 cluster(s)                3               3\n3 cluster(s)                1               1\n\n-------------------\n\nSituation 43\nNum Clusters:  3\nNum Unique Authors:  4\nPrecision:  0.25854700854700857\nRecall:  0.32142857142857145\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n3 cluster(s)                2               2\n\n-------------------\n\nSituation 44\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.15193798449612403\nRecall:  0.27906976744186046\n              mis_integration  mis_separation\n2 cluster(s)                3               4\n\n-------------------\n\nSituation 45\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.26054054054054054\nRecall:  0.35135135135135137\n              mis_integration  mis_separation\n1 cluster(s)                1               2\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 46\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.1442577030812325\nRecall:  0.23684210526315788\n              mis_integration  mis_separation\n1 cluster(s)              NaN             1.0\n2 cluster(s)              3.0             3.0\n\n-------------------\n\nSituation 47\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.6666666666666666\nRecall:  0.6666666666666666\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 48\nNum Clusters:  3\nNum Unique Authors:  4\nPrecision:  0.23088023088023088\nRecall:  0.24242424242424243\n              mis_integration  mis_separation\n1 cluster(s)                1               2\n3 cluster(s)                2               2\n\n-------------------\n\nSituation 49\nNum Clusters:  2\nNum Unique Authors:  4\nPrecision:  0.16666666666666666\nRecall:  0.2857142857142857\n              mis_integration  mis_separation\n2 cluster(s)                3               4\n\n-------------------\n\n\n\nTotal Precision: 0.2641815841179928\tTotal Recall: 0.3941544915423887\n                 2 cluster(s)\nmis_integration           1.0\nmis_separation            1.0\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.316337997605367"
          },
          "metadata": {},
          "execution_count": 181
        }
      ],
      "source": [
        "metric_eval_2.get_metrics_many(y_hat_comb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FINDING THE BEST EPSILON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "urning Similarity Matrix.\nNumber of pairs after cleaning:  2916\nProcessing combination number 27 from 50\nTotal number of papers:  56\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  3136\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  3136\nProcessing combination number 28 from 50\nTotal number of papers:  55\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  3025\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  3025\nProcessing combination number 29 from 50\nTotal number of papers:  60\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  3600\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  3600\nProcessing combination number 30 from 50\nTotal number of papers:  57\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  3249\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  3249\nProcessing combination number 31 from 50\nTotal number of papers:  60\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  3600\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  3600\nProcessing combination number 32 from 50\nTotal number of papers:  57\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  3249\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  3249\nProcessing combination number 33 from 50\nTotal number of papers:  29\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  841\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  841\nProcessing combination number 34 from 50\nTotal number of papers:  64\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  4096\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  4096\nProcessing combination number 35 from 50\nTotal number of papers:  27\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  729\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  729\nProcessing combination number 36 from 50\nTotal number of papers:  56\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  3136\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  3136\nProcessing combination number 37 from 50\nTotal number of papers:  59\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  3481\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  3481\nProcessing combination number 38 from 50\nTotal number of papers:  57\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  3249\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  3249\nProcessing combination number 39 from 50\nTotal number of papers:  61\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  3721\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  3721\nProcessing combination number 40 from 50\nTotal number of papers:  61\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  3721\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  3721\nProcessing combination number 41 from 50\nTotal number of papers:  60\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  3600\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  3600\nProcessing combination number 42 from 50\nTotal number of papers:  59\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  3481\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  3481\nProcessing combination number 43 from 50\nTotal number of papers:  56\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  3136\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  3136\nProcessing combination number 44 from 50\nTotal number of papers:  63\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  3969\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  3969\nProcessing combination number 45 from 50\nTotal number of papers:  58\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  3364\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  3364\nProcessing combination number 46 from 50\nTotal number of papers:  56\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  3136\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  3136\nProcessing combination number 47 from 50\nTotal number of papers:  62\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  3844\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  3844\nProcessing combination number 48 from 50\nTotal number of papers:  57\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  3249\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  3249\nProcessing combination number 49 from 50\nTotal number of papers:  58\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  3364\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  3364\nProcessing combination number 50 from 50\nTotal number of papers:  59\nBuilding Same Author Column\nNumber of paper combinations (pre-cleaning) is:  3481\nGetting Similarities\nComparing Authors\nComparing Mesh\nComparing Forenames\nComparing Institutions\nComparing Emails\nComparing Countries\nKeeping Doubles\nReturning Similarity Matrix.\nNumber of pairs after cleaning:  3481\nSituation 0\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.27437641723356015\nRecall:  0.5238095238095238\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 1\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.2941683424303361\nRecall:  0.5423728813559322\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 2\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.4909090909090909\nRecall:  0.4909090909090909\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 3\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.8888888888888888\nRecall:  0.8888888888888888\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 4\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.8545454545454545\nRecall:  0.8545454545454545\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 5\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.7056530214424951\nRecall:  0.7017543859649122\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 6\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.864406779661017\nRecall:  0.864406779661017\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 7\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.25\nRecall:  0.5\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 8\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.9460798460798461\nRecall:  0.9454545454545454\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 9\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.6296296296296297\nRecall:  0.6296296296296297\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 10\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.25\nRecall:  0.5\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 11\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.27437641723356015\nRecall:  0.5238095238095238\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 12\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.25\nRecall:  0.5\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 13\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.25775147928994085\nRecall:  0.5076923076923077\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 14\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.25\nRecall:  0.5\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 15\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.9080357142857144\nRecall:  0.9\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 16\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.875\nRecall:  0.875\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 17\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.2941683424303361\nRecall:  0.5423728813559322\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 18\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.7704918032786885\nRecall:  0.7704918032786885\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 19\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.9051075268817205\nRecall:  0.9032258064516129\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 20\nNum Clusters:  1\nNum Unique Authors:  1\nPrecision:  1.0\nRecall: 1.0\n              mis_integration  mis_separation\n1 cluster(s)                1               1\n\n-------------------\n\nSituation 21\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.265869140625\nRecall:  0.515625\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 22\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.5576767142605323\nRecall:  0.5573770491803278\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 23\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.5806451612903226\nRecall:  0.5806451612903226\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 24\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.6825396825396826\nRecall:  0.6825396825396826\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 25\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.9629629629629629\nRecall:  0.9629629629629629\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 26\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.2681760204081633\nRecall:  0.5178571428571429\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 27\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.5272727272727272\nRecall:  0.5272727272727272\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 28\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.30250000000000005\nRecall:  0.55\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 29\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.5789473684210527\nRecall:  0.5789473684210527\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 30\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.8333333333333334\nRecall:  0.8333333333333334\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 31\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.5266398755509464\nRecall:  0.5263157894736842\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 32\nNum Clusters:  1\nNum Unique Authors:  1\nPrecision:  1.0\nRecall:  1.0\n              mis_integration  mis_separation\n1 cluster(s)                1               1\n\n-------------------\n\nSituation 33\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.25\nRecall:  0.5\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 34\nNum Clusters:  1\nNum Unique Authors:  1\nPrecision:  1.0\nRecall:  1.0\n              mis_integration  mis_separation\n1 cluster(s)                1               1\n\n-------------------\n\nSituation 35\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.2681760204081633\nRecall:  0.5178571428571429\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 36\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.6783557373855444\nRecall:  0.6779661016949152\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 37\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.6491228070175439\nRecall:  0.6491228070175439\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 38\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.2751948400967482\nRecall:  0.5245901639344263\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 39\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.2926632625638269\nRecall:  0.5409836065573771\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 40\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.30250000000000005\nRecall:  0.55\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 41\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.2760700948003447\nRecall:  0.5254237288135594\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 42\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.8214285714285714\nRecall:  0.8214285714285714\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 43\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.25799949609473416\nRecall:  0.5079365079365079\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 44\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.25\nRecall:  0.5\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 45\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.2681760204081633\nRecall:  0.5178571428571429\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 46\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.28329864724245574\nRecall:  0.532258064516129\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 47\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.9173489278752437\nRecall:  0.9122807017543859\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\nSituation 48\nNum Clusters:  1\nNum Unique Authors:  2\nPrecision:  0.28567181926278234\nRecall:  0.5344827586206896\n              mis_integration  mis_separation\n1 cluster(s)                2               2\n\n-------------------\n\nSituation 49\nNum Clusters:  2\nNum Unique Authors:  2\nPrecision:  0.7565521029504081\nRecall:  0.7457627118644068\n              mis_integration  mis_separation\n2 cluster(s)                2               2\n\n-------------------\n\n\n\nTotal Precision: 0.5430542017683906\tTotal Recall: 0.6571037945998218\n                 2 cluster(s)\nmis_integration           1.0\nmis_separation            1.0\n"
        }
      ],
      "source": [
        "eps = np.linspace(.45,.55,20)\n",
        "best_eps = None\n",
        "best_F1 = 0.0\n",
        "memory_f1 = []\n",
        "\n",
        "# TODO: Try to learn eps from all use_cases (once we deal with getting the right weights for ua/da cases) \n",
        "\n",
        "for i,ep in enumerate(eps):\n",
        "    print(\"Up to trial # \", i)\n",
        "    #@blockPrinting\n",
        "    y_hat_comb = db_scan_3.db_multiple(ps,df,use_case=\"2_da_same\",num_cases = 50,model=best_model,epsilon=ep)\n",
        "    #@blockPrinting\n",
        "    f1_score = metric_eval_2.get_metrics_many(y_hat_comb)\n",
        "    memory_f1.append(f1_score)\n",
        "    if f1_score > best_F1:\n",
        "        best_F1 = f1_score\n",
        "        best_eps = ep\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "And the best epsilon for this use case is:  0.45\n"
        }
      ],
      "source": [
        "print(\"And the best epsilon for this use case is: \", best_eps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([0.45      , 0.45526316, 0.46052632, 0.46578947, 0.47105263,\n       0.47631579, 0.48157895, 0.48684211, 0.49210526, 0.49736842,\n       0.50263158, 0.50789474, 0.51315789, 0.51842105, 0.52368421,\n       0.52894737, 0.53421053, 0.53947368, 0.54473684, 0.55      ])"
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "eps = np.linspace(.45,.55,20)\n",
        "eps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "[0.6698369194131806,\n 0.6698369194131806,\n 0.6698369194131806,\n 0.6698369194131806,\n 0.6698369194131806,\n 0.6698369194131806,\n 0.6698369194131806,\n 0.6698369194131806,\n 0.6698369194131806,\n 0.6600933631184451,\n 0.6499414848769652,\n 0.6464487691212423,\n 0.6464487691212423,\n 0.6348093469816667,\n 0.6297929542901801,\n 0.6279439411363853,\n 0.616034946917185,\n 0.6023448274764495,\n 0.6023448274764495,\n 0.5946599993254658]"
          },
          "metadata": {},
          "execution_count": 229
        }
      ],
      "source": [
        "memory_f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see it is decreasing in F1 Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EXPLORING DATA (SIDE PROJ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "Index(['Dong, X', 'Donowitz, M', 'Gupta, S', 'Lu, H', 'Smith, SA', 'Tang, J',\n       'Vijg, J', 'Vonderheide, RH', 'Zhou, Y'],\n      dtype='object', name='last_author_name')"
          },
          "metadata": {},
          "execution_count": 116
        }
      ],
      "source": [
        "unique_authors = df.groupby('last_author_name')[[\"PI_IDS\"]].nunique()\n",
        "unique_authors = unique_authors[unique_authors[\"PI_IDS\"] == 3].index\n",
        "indie_authors = df[df['last_author_name'].isin(unique_authors)].groupby(['last_author_name','PI_IDS'])[['pmid']]                                                                  .nunique().reset_index(1)\n",
        "\n",
        "indie_authors2 = indie_authors.join(indie_authors, lsuffix=\"_l\", rsuffix='_r')\n",
        "indie_authors = indie_authors2.join(indie_authors, lsuffix=\"_l\", rsuffix='_r').reset_index()\n",
        "\n",
        "indie_authors = indie_authors[(indie_authors[\"PI_IDS_l\"] != indie_authors[\"PI_IDS_r\"]) & \\\n",
        "                              (indie_authors[\"PI_IDS_l\"] != indie_authors[\"PI_IDS\"]) & \\\n",
        "                              (indie_authors[\"PI_IDS_r\"] != indie_authors[\"PI_IDS\"])].drop_duplicates(\"last_author_name\",keep=\"first\")                                                                                        .set_index('last_author_name')\n",
        "\n",
        "possible_authors_same = indie_authors[(indie_authors[\"pmid_l\"] > 3) & \\\n",
        "                                      (indie_authors[\"pmid_r\"] > 3) & \\\n",
        "                                      (indie_authors[\"pmid\"] > 3)]\n",
        "\n",
        "possible_authors_same.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "         pmid last_author_country    PI_IDS last_author_name  \\\n414  30030371                  MD   1858737      Donowitz, M   \n415  30030371                  MD  10240590      Donowitz, M   \n416  30030371                  MD  10240585      Donowitz, M   \n\n                                               authors   doi  \\\n414  [{'forename': 'Varsha', 'affiliation': 'Depart...  None   \n415  [{'forename': 'Varsha', 'affiliation': 'Depart...  None   \n416  [{'forename': 'Varsha', 'affiliation': 'Depart...  None   \n\n                journal_name language  \\\n414  Journal of cell science      eng   \n415  Journal of cell science      eng   \n416  Journal of cell science      eng   \n\n                                           last_author  \\\n414  {'affiliation': 'Departments of Medicine and P...   \n415  {'affiliation': 'Departments of Medicine and P...   \n416  {'affiliation': 'Departments of Medicine and P...   \n\n                          last_author_email  last_author_id  \\\n414  [mdonowit@jhmi.edu, vsingh11@jhmi.edu]       1657077.0   \n415  [mdonowit@jhmi.edu, vsingh11@jhmi.edu]       1657077.0   \n416  [mdonowit@jhmi.edu, vsingh11@jhmi.edu]       1657077.0   \n\n             last_author_inst  \\\n414  Johns Hopkins University   \n415  Johns Hopkins University   \n416  Johns Hopkins University   \n\n                                                  mesh  \\\n414  [Caco-2 Cells, Cell Membrane/drug effects, Cel...   \n415  [Caco-2 Cells, Cell Membrane/drug effects, Cel...   \n416  [Caco-2 Cells, Cell Membrane/drug effects, Cel...   \n\n                                            mesh_major  pub_year  \\\n414  [Cholera Toxin/pharmacology, Endosomes/drug ef...    2018.0   \n415  [Cholera Toxin/pharmacology, Endosomes/drug ef...    2018.0   \n416  [Cholera Toxin/pharmacology, Endosomes/drug ef...    2018.0   \n\n                                                 title  \n414  Cholera toxin inhibits SNX27-retromer-mediated...  \n415  Cholera toxin inhibits SNX27-retromer-mediated...  \n416  Cholera toxin inhibits SNX27-retromer-mediated...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pmid</th>\n      <th>last_author_country</th>\n      <th>PI_IDS</th>\n      <th>last_author_name</th>\n      <th>authors</th>\n      <th>doi</th>\n      <th>journal_name</th>\n      <th>language</th>\n      <th>last_author</th>\n      <th>last_author_email</th>\n      <th>last_author_id</th>\n      <th>last_author_inst</th>\n      <th>mesh</th>\n      <th>mesh_major</th>\n      <th>pub_year</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>414</th>\n      <td>30030371</td>\n      <td>MD</td>\n      <td>1858737</td>\n      <td>Donowitz, M</td>\n      <td>[{'forename': 'Varsha', 'affiliation': 'Depart...</td>\n      <td>None</td>\n      <td>Journal of cell science</td>\n      <td>eng</td>\n      <td>{'affiliation': 'Departments of Medicine and P...</td>\n      <td>[mdonowit@jhmi.edu, vsingh11@jhmi.edu]</td>\n      <td>1657077.0</td>\n      <td>Johns Hopkins University</td>\n      <td>[Caco-2 Cells, Cell Membrane/drug effects, Cel...</td>\n      <td>[Cholera Toxin/pharmacology, Endosomes/drug ef...</td>\n      <td>2018.0</td>\n      <td>Cholera toxin inhibits SNX27-retromer-mediated...</td>\n    </tr>\n    <tr>\n      <th>415</th>\n      <td>30030371</td>\n      <td>MD</td>\n      <td>10240590</td>\n      <td>Donowitz, M</td>\n      <td>[{'forename': 'Varsha', 'affiliation': 'Depart...</td>\n      <td>None</td>\n      <td>Journal of cell science</td>\n      <td>eng</td>\n      <td>{'affiliation': 'Departments of Medicine and P...</td>\n      <td>[mdonowit@jhmi.edu, vsingh11@jhmi.edu]</td>\n      <td>1657077.0</td>\n      <td>Johns Hopkins University</td>\n      <td>[Caco-2 Cells, Cell Membrane/drug effects, Cel...</td>\n      <td>[Cholera Toxin/pharmacology, Endosomes/drug ef...</td>\n      <td>2018.0</td>\n      <td>Cholera toxin inhibits SNX27-retromer-mediated...</td>\n    </tr>\n    <tr>\n      <th>416</th>\n      <td>30030371</td>\n      <td>MD</td>\n      <td>10240585</td>\n      <td>Donowitz, M</td>\n      <td>[{'forename': 'Varsha', 'affiliation': 'Depart...</td>\n      <td>None</td>\n      <td>Journal of cell science</td>\n      <td>eng</td>\n      <td>{'affiliation': 'Departments of Medicine and P...</td>\n      <td>[mdonowit@jhmi.edu, vsingh11@jhmi.edu]</td>\n      <td>1657077.0</td>\n      <td>Johns Hopkins University</td>\n      <td>[Caco-2 Cells, Cell Membrane/drug effects, Cel...</td>\n      <td>[Cholera Toxin/pharmacology, Endosomes/drug ef...</td>\n      <td>2018.0</td>\n      <td>Cholera toxin inhibits SNX27-retromer-mediated...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "df_core.head(3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMDB4SeVJCVxRCeLtwZTVEo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python36064bitfbb4224caa94405ca5a0ec832b3f454b",
      "display_name": "Python 3.6.0 64-bit"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
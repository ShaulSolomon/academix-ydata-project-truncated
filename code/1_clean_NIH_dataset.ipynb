{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clean_NIH_dataset.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgranit/academix-ydata-project/blob/master/code/1_clean_NIH_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EciuGa5hL6Xk",
        "colab_type": "text"
      },
      "source": [
        "<h3>Outline</h3>\n",
        "\n",
        "From NIH merged database, take PI_NAMEs and create a new column `cleaned_name` which:\n",
        "1. Removes any parenthesis or extra information from names (that includes possible other last names for researcher)\n",
        "2. Turns TUAN, ROCKY S -> Tuan, RS\n",
        "3. If there are several names, it keeps them in the same cell with a ';' as a divider. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sLkgRNWMw5p",
        "colab_type": "text"
      },
      "source": [
        "## Initializations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72UixsP-uoMa",
        "colab_type": "code",
        "outputId": "4569ba15-090f-4ce8-8119-52665ccb70eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "import os, urllib, glob, sys\n",
        "from getpass import getpass\n",
        "\n",
        "user = input('User name: ')\n",
        "password = getpass('Password: ')\n",
        "password = urllib.parse.quote(password) # your password is converted into url format\n",
        "cmd_string = \"! git clone https://{0}:{1}@github.com/rgranit/academix-ydata-project AYP\".format(user, password)\n",
        "\n",
        "os.system(cmd_string)\n",
        "cmd_string, password = \"\", \"\" # removing the password from the variable\n",
        "\n",
        "% cd '/content/AYP/code'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User name: ShaulSolomon\n",
            "Password: ··········\n",
            "/content/AYP/code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08rEd1qi5Zne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' Initializations '''\n",
        "import os, sys, glob\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#sys.path.append('./code/')\n",
        "import utils\n",
        "\n",
        "PATH = \"data/labeled_dataset/\"\n",
        "FILE = 'NIH_precleaning_large.csv'\n",
        "OUT_PATH = \"data/labeled_dataset/\"\n",
        "OUT_FILE = 'NIH_postcleaning_large.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt5Ca_dNyOnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tH6oPdvvHHf",
        "colab_type": "code",
        "outputId": "0237dfe1-3ae3-4b60-ee10-d95b43ebda01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "if os.path.exists(PATH + FILE):\n",
        "    print(\"Getting local file...\")\n",
        "    df = pd.read_csv(PATH+FILE)\n",
        "    df.drop('Unnamed: 0',axis=1, inplace=True)\n",
        "else:\n",
        "    print(\"Getting File from S3...\")\n",
        "    df = utils.get_dataframe_from_s3(file=FILE)\n",
        "    df.drop('Unnamed: 0',axis=1, inplace=True)\n",
        "print(\"File recieved\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting File from S3...\n",
            "File recieved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvn13nX31vTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4loiBND98HfO",
        "colab_type": "code",
        "outputId": "a152b323-f461-492b-e3eb-537c8c695dc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "print(df.head())\n",
        "print(df.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       PMID PROJECT_NUMBER    FY ORG_STATE    PI_IDS        PI_NAMEs\n",
            "0  19415686    ZIAAR041131  2009       NaN  1858712;  TUAN, ROCKY S;\n",
            "1  19650110    ZIAAR041131  2009       NaN  1858712;  TUAN, ROCKY S;\n",
            "2  19283731    ZIAAR041131  2009       NaN  1858712;  TUAN, ROCKY S;\n",
            "3  19274753    ZIAAR041131  2009       NaN  1858712;  TUAN, ROCKY S;\n",
            "4  19479830    ZIAAR041131  2009       NaN  1858712;  TUAN, ROCKY S;\n",
            "(22172394, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayEV2GCRPgF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def separate_names(names):\n",
        "  '''\n",
        "  Input: a name \"LASTNAME, FIRSTNAME MIDDLENAME|MIDDLE_INITIAL;\" ex: TUAN, ROCKY S\n",
        "  Return: \"Lastname, Firstinitial_Middleinitial\" ex: Tuan, RS\n",
        "  '''\n",
        "  try:\n",
        "    cleaned_name = \"\"\n",
        "    each_name = names.strip().replace(', ', ' ').split(' ')\n",
        "    if (len(each_name) == 1):\n",
        "      #Only has a last name\n",
        "      cleaned_name = np.NaN\n",
        "      ### We consider this data unfit and need to remove it right after. ###\n",
        "\n",
        "    #Due to having bugging issue with sub-arrays and strip columns, inside each name the divider between last name and first name will be !(which will be returned to , after .exploding() rows)  \n",
        "    elif (len(each_name) == 2):\n",
        "      #Just has a last name and a first name\n",
        "      cleaned_name = each_name[0].capitalize() + \"! \" + each_name[1][0].upper()\n",
        "    else:\n",
        "      if len(each_name[2]) == 1:\n",
        "        #If it's a middle initial\n",
        "        cleaned_name = each_name[0].capitalize() + \"! \" + each_name[1][0].upper() + each_name[2].upper()\n",
        "      else:\n",
        "        #If it's a middle name\n",
        "        cleaned_name = each_name[0].capitalize() + \"! \" + each_name[1][0].upper() + each_name[2][0].upper()\n",
        "  except:\n",
        "    print(names)\n",
        "  return cleaned_name\n",
        "\n",
        "def clean_name(name):\n",
        "  '''\n",
        "  PI_NAMEs can have several names at the Private investigators.\n",
        "  input: A cell of df[\"PI_NAMEs\"]\n",
        "  output: cleaned version of each PI in \"PI_NAMEs\"\n",
        "  '''\n",
        "  if type(name) != 'str':\n",
        "    name = str(name)\n",
        "  name = name.lower()\n",
        "  names = name.split(';')\n",
        "\n",
        "\n",
        "  #remove contact names in database\n",
        "  names = [re.sub(r'.*\\(contact\\).*',\"\",name) for name in names]\n",
        "  #remove optional other last name from name\n",
        "  names = [re.sub(r' \\(.*\\)',\"\",name) for name in names]\n",
        "  #remove extra spaces\n",
        "  names = [re.sub(r' +',' ',name) for name in names]\n",
        "  #for the few cases where have \" , \" instead of \", \"\n",
        "  names = [re.sub(r' , ',', ',name) for name in names]\n",
        "  #remove empty strings\n",
        "  names = list(filter(lambda x: x != \"\", names))\n",
        "\n",
        "\n",
        "  if len(names) == 0:\n",
        "    print(\"ERROR WITH NAME: \", name)\n",
        "    return \"ERROR WITH NAME\"\n",
        "\n",
        "  elif len(names) == 1:\n",
        "    new_name = separate_names(names[0])\n",
        "      \n",
        "  else:\n",
        "    new_name = \"\"\n",
        "    for name in names:\n",
        "      added_name = separate_names(name)\n",
        "      # We want unfit names to get a 'nan' value so we can drop them, but will many people, we want to skip the name\n",
        "      if isinstance(added_name,str):\n",
        "        new_name += added_name + \",\"\n",
        "\n",
        "  return new_name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlJKe_alZv0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['cleaned_name'] = [clean_name(name) for name in df['PI_NAMEs']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bGb8mLh1r7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get rid of NaN data\n",
        "df.dropna(inplace=True)\n",
        "df.loc[df.cleaned_name.isna()]\n",
        "\n",
        "#Weirdly, the PI_IDS themselves were unclean, with empty spaces at the end, .strip() cleans it\n",
        "df['PI_IDS'] = [x.strip() for x in df['PI_IDS']]\n",
        "df['cleaned_name'] = [x.strip(',') for x in df['cleaned_name']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5EaJZWssOSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drop duplicates\n",
        "df.drop_duplicates(subset=['PMID','PROJECT_NUMBER','PI_IDS','ORG_STATE'],keep='first',inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBqxdliKGrsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = df.copy()\n",
        "df2 = df2[['PMID',\"PI_IDS\",\"cleaned_name\",\"ORG_STATE\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlu684mwHK_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#change the delimeter in ids to , and not ;\n",
        "df2['PI_IDS'] = [re.sub(\";\", \",\",x.strip(\";\")) for x in df2['PI_IDS']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lYm-b__Hq-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove (contact) ids from the dataframe\n",
        "df2['PI_IDS'] = [re.sub(\", [0-9]+ *\\(contact\\)\",\"\",x) for x in df2['PI_IDS']]\n",
        "df2['PI_IDS'] = [re.sub(\"[0-9]+ \\(contact\\),\",\"\",x) for x in df2['PI_IDS']]\n",
        "df2['PI_IDS'] = [re.sub(\"[0-9]+ \\(contact\\)\",\"\",x) for x in df2['PI_IDS']]\n",
        "df2['PI_IDS'] = [x.strip(\",\") for x in df2['PI_IDS']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtCXrIVuf3Su",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#find how many rows have several values in them.\n",
        "idx_multiple_val = [\",\" in x for x in df2[\"PI_IDS\"]]\n",
        "df_multiple = df2[idx_multiple_val]\n",
        "idx_single_val = [\",\" not in x for x in df2[\"PI_IDS\"]]\n",
        "df_single = df2[idx_single_val]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP5d64it74SS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#breaks row with multiple values into multiple rows\n",
        "df_multiple = df_multiple.set_index(['PMID','ORG_STATE']).apply(lambda x: x.str.split(',').explode()).reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZX-m85xpPTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "merged_df = pd.concat([df_multiple,df_single])\n",
        "merged_df.drop_duplicates(keep=\"first\",inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uopDp1FDpVrk",
        "colab_type": "code",
        "outputId": "841e2b31-8fee-4d26-eb67-ceb64ecf3e43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.any(merged_df.duplicated())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uAZXVxNqlB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Return the name back to ',' from '!'\n",
        "merged_df['cleaned_name'] = [re.sub(\"!\",\",\",x) for x in merged_df['cleaned_name']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZVVac4LXt97",
        "colab_type": "text"
      },
      "source": [
        "## Uploading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6ILIv_RAvk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "merged_df.to_csv(OUT_PATH + OUT_FILE)\n",
        "file = open(OUT_PATH + OUT_FILE, 'r+', encoding='utf-8')\n",
        "utils.upload_to_s3(file=file,key = OUT_FILE)\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
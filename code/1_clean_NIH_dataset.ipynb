{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgranit/academix-ydata-project/blob/master/code/1_clean_NIH_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EciuGa5hL6Xk",
        "colab_type": "text"
      },
      "source": [
        "<h3>Outline</h3>\n",
        "\n",
        "From NIH merged database, take PI_NAMEs and create a new column `cleaned_name` which:\n",
        "1. Removes any parenthesis or extra information from names (that includes possible other last names for researcher)\n",
        "2. Turns TUAN, ROCKY S -> Tuan, RS\n",
        "3. If there are several names, it keeps them in the same cell with a ';' as a divider. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sLkgRNWMw5p",
        "colab_type": "text"
      },
      "source": [
        "## Initializations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72UixsP-uoMa",
        "colab_type": "code",
        "outputId": "b74cf11f-1162-4ef8-be53-180b7200c604",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# import os, urllib, glob, sys\n",
        "# from getpass import getpass\n",
        "\n",
        "# user = input('User name: ')\n",
        "# password = getpass('Password: ')\n",
        "# password = urllib.parse.quote(password) # your password is converted into url format\n",
        "# cmd_string = \"! git clone https://{0}:{1}@github.com/rgranit/academix-ydata-project AYP\".format(user, password)\n",
        "\n",
        "# os.system(cmd_string)\n",
        "# cmd_string, password = \"\", \"\" # removing the password from the variable\n",
        "\n",
        "# % cd '/content/AYP/code'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User name: ShaulSolomon\n",
            "Password: ··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08rEd1qi5Zne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' Initializations '''\n",
        "import os, sys, glob\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "sys.path.append('./code/')\n",
        "import s3_functions\n",
        "\n",
        "PATH = \"data/labeled_dataset/source_files/\"\n",
        "FILE = 'NIH_precleaning.csv'\n",
        "OUT_PATH = \"data/labeled_dataset/\"\n",
        "OUT_FILE = 'NIH_postcleaning.csv'"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tH6oPdvvHHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if os.path.exists(PATH + FILE):\n",
        "    print(\"Getting local file...\")\n",
        "    df = pd.read_csv(PATH+FILE)\n",
        "    df.drop('Unnamed: 0',axis=1, inplace=True)\n",
        "else:\n",
        "    print(\"Getting File from S3...\")\n",
        "    df = s3_functions.get_dataframe_from_s3(file=FILE)\n",
        "    df.drop('Unnamed: 0',axis=1, inplace=True)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "File Exists...\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4loiBND98HfO",
        "colab_type": "code",
        "outputId": "9c27ab87-cbe3-4569-f5a6-f17973094598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(df.head())\n",
        "print(df.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PMID PROJECT_NUMBER    FY ORG_STATE     PI_IDS  \\\n0  25782559    U01CI000333  2009        MO   1946136;   \n1  19803722    U01CI000333  2009        MO   1946136;   \n2  19335165    U01CI000333  2009        MO   1946136;   \n3  26267390    R01DA007031  2015        AZ  3105734;    \n4  26267390    R01DA007031  2009        OR   1870683;   \n\n                     PI_NAMEs  \n0        FRASER, VICTORIA J.;  \n1        FRASER, VICTORIA J.;  \n2        FRASER, VICTORIA J.;  \n3  LEMERY-CHALFANT, KATHRYN ;  \n4          DISHION, THOMAS J;  \n(4166119, 6)\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "       PMID PROJECT_NUMBER    FY ORG_STATE     PI_IDS  \\\n0  25782559    U01CI000333  2009        MO   1946136;   \n1  19803722    U01CI000333  2009        MO   1946136;   \n2  19335165    U01CI000333  2009        MO   1946136;   \n3  26267390    R01DA007031  2015        AZ  3105734;    \n4  26267390    R01DA007031  2009        OR   1870683;   \n\n                     PI_NAMEs  \n0        FRASER, VICTORIA J.;  \n1        FRASER, VICTORIA J.;  \n2        FRASER, VICTORIA J.;  \n3  LEMERY-CHALFANT, KATHRYN ;  \n4          DISHION, THOMAS J;  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PMID</th>\n      <th>PROJECT_NUMBER</th>\n      <th>FY</th>\n      <th>ORG_STATE</th>\n      <th>PI_IDS</th>\n      <th>PI_NAMEs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25782559</td>\n      <td>U01CI000333</td>\n      <td>2009</td>\n      <td>MO</td>\n      <td>1946136;</td>\n      <td>FRASER, VICTORIA J.;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>19803722</td>\n      <td>U01CI000333</td>\n      <td>2009</td>\n      <td>MO</td>\n      <td>1946136;</td>\n      <td>FRASER, VICTORIA J.;</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19335165</td>\n      <td>U01CI000333</td>\n      <td>2009</td>\n      <td>MO</td>\n      <td>1946136;</td>\n      <td>FRASER, VICTORIA J.;</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>26267390</td>\n      <td>R01DA007031</td>\n      <td>2015</td>\n      <td>AZ</td>\n      <td>3105734;</td>\n      <td>LEMERY-CHALFANT, KATHRYN ;</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>26267390</td>\n      <td>R01DA007031</td>\n      <td>2009</td>\n      <td>OR</td>\n      <td>1870683;</td>\n      <td>DISHION, THOMAS J;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayEV2GCRPgF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def separate_names(names):\n",
        "  '''\n",
        "  Input: a name \"LASTNAME, FIRSTNAME MIDDLENAME|MIDDLE_INITIAL;\" ex: TUAN, ROCKY S\n",
        "  Return: \"Lastname, Firstinitial_Middleinitial\" ex: Tuan, RS\n",
        "  '''\n",
        "  try:\n",
        "    cleaned_name = \"\"\n",
        "    each_name = names.strip().replace(', ', ' ').split(' ')\n",
        "    if (len(each_name) == 1):\n",
        "      #Only has a last name\n",
        "      cleaned_name = np.NaN\n",
        "      ### We consider this data unfit and need to remove it right after. ###\n",
        "\n",
        "    #Due to having bugging issue with sub-arrays and strip columns, inside each name the divider between last name and first name will be !(which will be returned to , after .exploding() rows)  \n",
        "    elif (len(each_name) == 2):\n",
        "      #Just has a last name and a first name\n",
        "      cleaned_name = each_name[0].capitalize() + \"! \" + each_name[1][0].upper()\n",
        "    else:\n",
        "      if len(each_name[2]) == 1:\n",
        "        #If it's a middle initial\n",
        "        cleaned_name = each_name[0].capitalize() + \"! \" + each_name[1][0].upper() + each_name[2].upper()\n",
        "      else:\n",
        "        #If it's a middle name\n",
        "        cleaned_name = each_name[0].capitalize() + \"! \" + each_name[1][0].upper() + each_name[2][0].upper()\n",
        "  except:\n",
        "    print(names)\n",
        "  return cleaned_name\n",
        "\n",
        "def clean_name(name):\n",
        "  '''\n",
        "  PI_NAMEs can have several names at the Private investigators.\n",
        "  input: A cell of df[\"PI_NAMEs\"]\n",
        "  output: cleaned version of each PI in \"PI_NAMEs\"\n",
        "  '''\n",
        "  if type(name) != 'str':\n",
        "    name = str(name)\n",
        "  name = name.lower()\n",
        "  names = name.split(';')\n",
        "\n",
        "\n",
        "  #remove contact names in database\n",
        "  names = [re.sub(r'.*\\(contact\\).*',\"\",name) for name in names]\n",
        "  #remove optional other last name from name\n",
        "  names = [re.sub(r' \\(.*\\)',\"\",name) for name in names]\n",
        "  #remove extra spaces\n",
        "  names = [re.sub(r' +',' ',name) for name in names]\n",
        "  #for the few cases where have \" , \" instead of \", \"\n",
        "  names = [re.sub(r' , ',', ',name) for name in names]\n",
        "  #remove empty strings\n",
        "  names = list(filter(lambda x: x != \"\", names))\n",
        "\n",
        "\n",
        "  if len(names) == 0:\n",
        "    print(\"ERROR WITH NAME: \", name)\n",
        "    return \"ERROR WITH NAME\"\n",
        "\n",
        "  elif len(names) == 1:\n",
        "    new_name = separate_names(names[0])\n",
        "      \n",
        "  else:\n",
        "    new_name = \"\"\n",
        "    for name in names:\n",
        "      added_name = separate_names(name)\n",
        "      # We want unfit names to get a 'nan' value so we can drop them, but will many people, we want to skip the name\n",
        "      if isinstance(added_name,str):\n",
        "        new_name += added_name + \",\"\n",
        "\n",
        "  return new_name"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlJKe_alZv0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['cleaned_name'] = [clean_name(name) for name in df['PI_NAMEs']]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bGb8mLh1r7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get rid of NaN data\n",
        "df.dropna(inplace=True)\n",
        "df.loc[df.cleaned_name.isna()]\n",
        "\n",
        "#Weirdly, the PI_IDS themselves were unclean, with empty spaces at the end, .strip() cleans it\n",
        "df['PI_IDS'] = [x.strip() for x in df['PI_IDS']]\n",
        "df['cleaned_name'] = [x.strip(',') for x in df['cleaned_name']]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5EaJZWssOSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drop duplicates\n",
        "df.drop_duplicates(subset=['PMID','PROJECT_NUMBER','PI_IDS','ORG_STATE'],keep='first',inplace=True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBqxdliKGrsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = df.copy()\n",
        "df2 = df2[['PMID',\"PI_IDS\",\"cleaned_name\",\"ORG_STATE\"]]"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlu684mwHK_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#change the delimeter in ids to , and not ;\n",
        "df2['PI_IDS'] = [re.sub(\";\", \",\",x.strip(\";\")) for x in df2['PI_IDS']]"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lYm-b__Hq-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove (contact) ids from the dataframe\n",
        "df2['PI_IDS'] = [re.sub(\", [0-9]+ *\\(contact\\)\",\"\",x) for x in df2['PI_IDS']]\n",
        "df2['PI_IDS'] = [re.sub(\"[0-9]+ \\(contact\\),\",\"\",x) for x in df2['PI_IDS']]\n",
        "df2['PI_IDS'] = [re.sub(\"[0-9]+ \\(contact\\)\",\"\",x) for x in df2['PI_IDS']]\n",
        "df2['PI_IDS'] = [x.strip(\",\") for x in df2['PI_IDS']]"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtCXrIVuf3Su",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#find how many rows have several values in them.\n",
        "idx_multiple_val = [\",\" in x for x in df2[\"PI_IDS\"]]\n",
        "df_multiple = df2[idx_multiple_val]\n",
        "idx_single_val = [\",\" not in x for x in df2[\"PI_IDS\"]]\n",
        "df_single = df2[idx_single_val]"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP5d64it74SS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#breaks row with multiple values into multiple rows\n",
        "df_multiple = df_multiple.set_index(['PMID','ORG_STATE']).apply(lambda x: x.str.split(',').explode()).reset_index()"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZX-m85xpPTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "merged_df = pd.concat([df_multiple,df_single])\n",
        "merged_df.drop_duplicates(keep=\"first\",inplace=True)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uopDp1FDpVrk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a977ea6-ffb9-4b19-b3f9-7b3d81125c11"
      },
      "source": [
        "np.any(merged_df.duplicated())"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "False"
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uAZXVxNqlB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Return the name back to ',' from '!'\n",
        "merged_df['cleaned_name'] = [re.sub(\"!\",\",\",x) for x in merged_df['cleaned_name']]"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZVVac4LXt97",
        "colab_type": "text"
      },
      "source": [
        "## Uploading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6ILIv_RAvk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "merged_df.to_csv(OUT_PATH + OUT_FILE)\n",
        "file = open(OUT_PATH + OUT_FILE, 'r+', encoding='utf-8')\n",
        "s3_functions.upload_to_s3(file=file,key = OUT_FILE)\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "clean_NIH_dataset.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOFWYj+dun60PDJ1H8zTWOF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
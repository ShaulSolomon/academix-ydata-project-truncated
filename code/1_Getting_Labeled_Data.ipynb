{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgranit/academix-ydata-project/blob/master/code/1_Getting_Labeled_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6H50p81rVf6",
        "colab_type": "text"
      },
      "source": [
        " <h3> Outline</h3>\n",
        "\n",
        "Code to unzip the files pulled from the NIH database, merge them, and do a bit of cleaning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyDv71sLsI8L",
        "colab_type": "text"
      },
      "source": [
        "## Initilizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGFkbYhGrpCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' Initializations '''\n",
        "\n",
        "import pandas as pd\n",
        "import os, zipfile, glob\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "import s3_functions\n",
        "\n",
        "INPUT_PATH = \"C:/Users/shaul/Documents/GitHub/academix-ydata-project/data/labeled_dataset/source_files/\"\n",
        "OUTPUT_PATH = \"C:/Users/shaul/Documents/GitHub/academix-ydata-project/data/labeled_dataset/source_files_merged/\""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIJe_bmId-yY",
        "colab_type": "code",
        "outputId": "f9713635-0613-42a5-8956-02f84013ce9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# user = input('User name: ')\n",
        "# password = getpass('Password: ')\n",
        "# password = urllib.parse.quote(password) # your password is converted into url format\n",
        "# cmd_string = \"! git clone https://{0}:{1}@github.com/rgranit/academix-ydata-project AYP\".format(user, password)\n",
        "\n",
        "# os.system(cmd_string)\n",
        "# cmd_string, password = \"\", \"\" # removing the password from the variable\n",
        "\n",
        "# %cd /content/AYP"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User name: ShaulSolomon\n",
            "Password: ··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ0DxhyJsOlP",
        "colab_type": "text"
      },
      "source": [
        "## Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZwrlqCy22ZB",
        "colab_type": "text"
      },
      "source": [
        "Databases were scraped from:\n",
        "https://exporter.nih.gov/ExPORTER_Catalog.aspx?sid=0&index=5<br>\n",
        "https://exporter.nih.gov/ExPORTER_Catalog.aspx?sid=5&index=0\n",
        "\n",
        "Data was only taken from three years '09 - '15' - '18 <br>\n",
        "\n",
        "(There is a theoretical other dataset on the publications themselves, if we so need).\n",
        "\n",
        "Details on database metadata: https://exporter.nih.gov/about.aspx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3FIfCZPsCzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzip all the files within the local folder\n",
        "\n",
        "extension = \".zip\"\n",
        "\n",
        "for item in os.listdir(INPUT_PATH): # loop through items in dir\n",
        "    if item.endswith(extension): # check for \".zip\" extension\n",
        "        zip_ref = zipfile.ZipFile(INPUT_PATH + item) # create zipfile object\n",
        "        zip_ref.extractall(PATH) # extract file to dir\n",
        "        zip_ref.close() # close file"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VulUjqzsa8X",
        "colab_type": "code",
        "outputId": "26fc00b7-e75a-48b8-8c0e-c214e62d60a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "#Iterating through the unzipped files, combine them into a single dataframe and then merge them.\n",
        "\n",
        "link_files = glob.glob(INPUT_PATH + \"RePORTER_PUBLNK_C_20*.csv\")\n",
        "prj_files = glob.glob(INPUT_PATH + \"RePORTER_PRJ_C_FY20*.csv\")\n",
        "\n",
        "lf=[]\n",
        "prjf = []\n",
        "\n",
        "print(\"loading PUBLINK files...\")\n",
        "for filename in link_files:\n",
        "    df = pd.read_csv(filename, index_col=None, header=0)\n",
        "    lf.append(df)\n",
        "lf_total = pd.concat(lf, axis=0, ignore_index=True)\n",
        "print(lf_total.head())\n",
        "\n",
        "print('\\n----------------------\\n')\n",
        "\n",
        "print(\"loading PRJ files (taking ['CORE_PROJECT_NUM','FY','PI_IDS', 'PI_NAMEs', 'ORG_STATE'] )...\")\n",
        "for filename in prj_files:\n",
        "    df = pd.read_csv(filename, index_col=None, header=0,encoding = 'ISO-8859-1', usecols=[\"CORE_PROJECT_NUM\",\"FY\",\"PI_IDS\", \"PI_NAMEs\", \"ORG_STATE\"] )\n",
        "    prjf.append(df)\n",
        "prjf_total = pd.concat(prjf, axis=0, ignore_index=True)\n",
        "prjf_total = prjf_total.rename(columns = {'CORE_PROJECT_NUM':'PROJECT_NUMBER'})\n",
        "print(prjf_total.head())\n",
        "\n",
        "print('\\n----------------------\\n')\n",
        "\n",
        "\n",
        "print(\"merging the dataframes...\")\n",
        "df = pd.merge(lf_total, prjf_total, how='inner', on ='PROJECT_NUMBER')\n",
        "print(df.head(10))\n",
        "\n",
        "df.to_csv(OUTPUT_PATH + 'NIH_precleaning.csv',encoding='utf-8')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "loading PUBLINK files...\n       PMID PROJECT_NUMBER\n0  19415686    ZIAAR041131\n1  19387461    ZIADK054511\n2  19936044    ZIAAI000361\n3  19783984    ZIANS002945\n4  19281132    ZIAES102225\n\n----------------------\n\nloading PRJ files...\n      PROJECT_NUMBER    FY ORG_STATE    PI_IDS             PI_NAMEs\n0  197NICS228-10-0-1  2009        MD         ;                  , ;\n1        C06RR020539  2009        CA  1859426;        PARK, NO-HEE;\n2        C06RR020540  2009        ME  1864471;     FORREST, JOHN N;\n3        C06RR020555  2009        VA  1889505;  MACRINA, FRANCIS L;\n4        C06RR020559  2009        NY  1961084;  MOORE, HOLLY MARIE;\n\n----------------------\n\nmerging the dataframes...\n       PMID PROJECT_NUMBER    FY ORG_STATE    PI_IDS         PI_NAMEs\n0  19415686    ZIAAR041131  2009       NaN  1858712;   TUAN, ROCKY S;\n1  19650110    ZIAAR041131  2009       NaN  1858712;   TUAN, ROCKY S;\n2  19283731    ZIAAR041131  2009       NaN  1858712;   TUAN, ROCKY S;\n3  19274753    ZIAAR041131  2009       NaN  1858712;   TUAN, ROCKY S;\n4  19479830    ZIAAR041131  2009       NaN  1858712;   TUAN, ROCKY S;\n5  19597468    ZIAAR041131  2009       NaN  1858712;   TUAN, ROCKY S;\n6  19107653    ZIAAR041131  2009       NaN  1858712;   TUAN, ROCKY S;\n7  19170141    ZIAAR041131  2009       NaN  1858712;   TUAN, ROCKY S;\n8  19415687    ZIAAR041131  2009       NaN  1858712;   TUAN, ROCKY S;\n9  19387461    ZIADK054511  2009       NaN  9415738;  LIANG, T. JAKE;\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2E68bnQT070",
        "colab_type": "code",
        "outputId": "1cdd4a50-5df0-40ad-b956-5566c7e73531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "f = open(OUTPUT_PATH + 'NIH_precleaning.csv', 'r+')\n",
        "s3_functions.upload_to_s3(file = f,key = \"NIH_precleaning.csv\")\n",
        "f.close()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-28-80c52c32f2ef>, line 1)",
          "traceback": [
            "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-28-80c52c32f2ef>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    f = open('C:\\Users\\shaul\\Documents\\GitHub\\academix-ydata-project\\data\\labeled_dataset\\source_files_merged\\NIH_precleaning.csv', 'r+')\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "1_Getting_Labeled_Data.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
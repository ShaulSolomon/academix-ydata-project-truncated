{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rgranit/academix-ydata-project/blob/master/code/3_Logisitic_Regression_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "cAW59VYVLUIJ",
    "outputId": "45c65b2d-4843-49fd-8785-fe19d986ef76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User name: ShaulSolomon\n",
      "Password: ··········\n"
     ]
    }
   ],
   "source": [
    "# import os, urllib, glob, sys\n",
    "# from getpass import getpass\n",
    "\n",
    "# user = input('User name: ')\n",
    "# password = getpass('Password: ')\n",
    "# password = urllib.parse.quote(password) # your password is converted into url format\n",
    "# cmd_string = \"! git clone https://{0}:{1}@github.com/rgranit/academix-ydata-project AYP\".format(user, password)\n",
    "\n",
    "# os.system(cmd_string)\n",
    "# cmd_string, password = \"\", \"\" # removing the password from the variable\n",
    "\n",
    "# %cd ./AYP/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path('/Users/roygranit/Desktop/ydata/industry_project/repo/academix-ydata-project/code/')\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q5hAha94LkS1"
   },
   "outputs": [],
   "source": [
    "import os, re, sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from yuval_module.paper_clusterer import PaperClusterer\n",
    "from yuval_module.paper_source import PaperSource\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as LogR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cluster import DBSCAN as DBS\n",
    "from collections import Counter \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from collections import defaultdict\n",
    "\n",
    "import py_3.sim_matrix_3 as sim_matrix_3\n",
    "import py_3.lr_model_3 as lr_model_3\n",
    "import py_3.db_scan_3 as db_scan_3\n",
    "import py_3.para_tuning_3 as para_tuning_3\n",
    "\n",
    "import yuval_module.dbscan as yuval_dbscan\n",
    "\n",
    "import pickle\n",
    "\n",
    "import metric_eval_2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import utils\n",
    "from utils import PROJECT_ROOT, DATA_PATH\n",
    "\n",
    "FILE = \"enriched_labeled_dataset_large.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/AYP\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PULLING FROM S3\n",
      "FILE PULLED\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(PROJECT_ROOT + DATA_PATH + FILE):\n",
    "    print(\"READING FROM LOCAL\")\n",
    "    if FILE.split(\".\")[1] == \"json\":\n",
    "        df = pd.read_json(PROJECT_ROOT + DATA_PATH + FILE)\n",
    "    else:\n",
    "        df = pd.read_csv(PROJECT_ROOT + DATA_PATH + FILE)\n",
    "    ps = PaperSource()\n",
    "else:\n",
    "    print(\"PULLING FROM S3\")\n",
    "    ps = sim_matrix_3.load_dataset(\"enriched_labeled_dataset_large\")\n",
    "    df = ps.get_dataset()\n",
    "\n",
    "df.drop(columns=[\"last_author_country\"],inplace=True)\n",
    "df.rename(columns={'ORG_STATE':'last_author_country'},inplace=True)\n",
    "\n",
    "print(\"FILE PULLED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/AYP/code\n"
     ]
    }
   ],
   "source": [
    "%cd code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecase = list(pd.read_csv(\"../data/test_set_author_names.csv\").drop(columns=[\"Unnamed: 0\"])[\"0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usecase = df[df['last_author_name'].isin(usecase)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = pd.read_csv(PROJECT_ROOT + \"data/hyper_parameters.csv\").set_index('Unnamed: 0').to_dict()['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = parameters['best_weights']\n",
    "w = re.sub(\" +\",\",\",weights)\n",
    "weights = eval('[' + w + ']')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.01442226, -0.06362535, -0.28114567, 0.03438976, -0.30097347, -0.09168013]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {}\n",
    "param_dict['author'], param_dict['mesh'], param_dict['inst'], param_dict['email'], param_dict['country'], __ = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = float(parameters['best_eps']) #epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seeing if we get rid of email\n",
    "param_dict['email'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Yuval's DBscan\n",
      "\n",
      "Comparing Authors\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2377 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing Mesh\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2377 [00:08<49:07,  1.24s/it]"
     ]
    }
   ],
   "source": [
    "# clusters_df=yuval_dbscan.run_db_scan(df_usecase, scaler=None)\n",
    "# clusters_df=metric_eval_2.assign_labels_to_clusters(clusters_df,clusters_df.cluster_pred.unique())\n",
    "# df_eval = metric_eval_2.get_metrics(clusters_df,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./models/train_scaler.pkl', 'rb') as input:\n",
    "    scaler = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/AYP/code/yuval_module/paper_clusterer.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  author_papers_df['last_author_forename']=author_papers_df['authors'].apply(lambda x: self.fetch_forename(x))\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "100%|██████████| 15/15 [00:00<00:00, 128.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing combination number 1 from 13\n",
      "Running Yuval's DBscan\n",
      "\n",
      "Comparing Authors\n",
      "\n",
      "Comparing Mesh\n",
      "\n",
      "Comparing Forenames\n",
      "\n",
      "Comparing Institutions\n",
      "\n",
      "Comparing Emails\n",
      "\n",
      "Comparing Countries\n",
      "\n",
      "77791     1\n",
      "171945    1\n",
      "171946    1\n",
      "171947    1\n",
      "171948    1\n",
      "171949    1\n",
      "178565    1\n",
      "178566    1\n",
      "178567    1\n",
      "178568    1\n",
      "178570    1\n",
      "178571    1\n",
      "178572    1\n",
      "178569    1\n",
      "187939    1\n",
      "Name: weight, dtype: int64\n",
      "77791     1\n",
      "171945    1\n",
      "171946    1\n",
      "171947    1\n",
      "171948    1\n",
      "171949    1\n",
      "178565    1\n",
      "178566    1\n",
      "178567    1\n",
      "178568    1\n",
      "178570    1\n",
      "178571    1\n",
      "178572    1\n",
      "178569    1\n",
      "187939    1\n",
      "Name: weight, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-a187196fd57d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muse_cases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0my_hat_comb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_papers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myuval_dbscan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_multiple_df_scan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_usecase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_cases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#,eps=eps,params=param_dict )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_eval_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metrics_many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat_comb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtotal_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_cases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_papers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AYP/code/yuval_module/dbscan.py\u001b[0m in \u001b[0;36mrun_multiple_df_scan\u001b[0;34m(ps, df, auth_df, scaler, use_case, num_cases, eps, params)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mcluster_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_db_scan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_auth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mcluster_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_db_scan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_auth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0my_hat_comb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_dfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pmid\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"PI_IDS\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"cluster_pred\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AYP/code/yuval_module/dbscan.py\u001b[0m in \u001b[0;36mrun_db_scan\u001b[0;34m(author_df, eps, gammas, scaler)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mpaper_clusterer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPaperClusterer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgammas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# dist matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mcombined_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_sim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaper_clusterer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dist_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthor_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;31m# cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mres_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_dfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpaper_clusterer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AYP/code/yuval_module/paper_clusterer.py\u001b[0m in \u001b[0;36mget_dist_matrix\u001b[0;34m(self, author_papers_df, just_sim_matrix_flag)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;31m#print(\"***\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;31m#print(for_clustering_df['weight'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mfor_clustering_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_by_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_dist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfor_clustering_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mtotal_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfor_clustering_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"db_cluster\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"cluster\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;31m#             total_df[\"cluster\"].fillna(-1.0, inplace=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AYP/code/yuval_module/paper_clusterer.py\u001b[0m in \u001b[0;36mcluster_by_sim\u001b[0;34m(self, combined_dist, df)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;31m#show_dist_to_nearest_neighbor_dist(combined_dist)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"db_cluster\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbscan_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AYP/code/yuval_module/paper_clusterer.py\u001b[0m in \u001b[0;36mdbscan_cluster\u001b[0;34m(self, dist, paper_weights)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;31m#                 dist= self.scaler.transform(dist)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaper_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0mclustering\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDBSCAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"precomputed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpaper_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclustering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/cluster/_dbscan.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"eps must be positive.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "total_metric = []\n",
    "use_cases = ['2_da_same','2_da_dif','3_da', '1_da','mix_bag']\n",
    "\n",
    "for case in use_cases:\n",
    "    y_hat_comb, num_cases, num_papers = yuval_dbscan.run_multiple_df_scan(ps,df, df_usecase,scaler = None,use_case=case,num_cases = 100)#,eps=eps,params=param_dict )\n",
    "    f1, precision, recall, df_eval = metric_eval_2.get_metrics_many(y_hat_comb)\n",
    "    total_metric.append([case,f1,precision,recall,df_eval,num_cases, num_papers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture cap --no-stderr\n",
    "\n",
    "for val in total_metric:\n",
    "    case, f1, prec, rec, df_eval, num_cases, num_papers = val\n",
    "    print(\"CASE: {}\\tNumber of authors: {}\\tNumber of papers: {}\".format(case,num_cases,num_papers))\n",
    "    print(\"\\nF1-Score: {}\\tTotal Precision: {}\\tTotal Recall: {}\".format(f1,prec,rec))\n",
    "    print(df_eval)\n",
    "    print(\"\\n\")   \n",
    "    \n",
    "    \n",
    "# with open('txt/test_scores_yuval_logr_model_july_12.txt', 'w') as out:\n",
    "#     out.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_yuval = 0.5\n",
    "param_dict_yuval = {\"author\":0.1,\"mesh\":0.11,\"inst\":-0.02,\"email\":-0.04,\"country\":-0.14,\"forename\":-0.1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters_df=yuval_dbscan.run_db_scan(df_core, \n",
    "#                                             eps=0.5,  \n",
    "#                                             gammas={\n",
    "#                                                     \"author\":0.1,\n",
    "#                                                     \"mesh\":0.11,\n",
    "#                                                     \"inst\":-0.02,\n",
    "#                                                     \"email\":-0.04,\n",
    "#                                                     \"country\":-0.14,\n",
    "#                                                     \"forename\":-0.1 })\n",
    "clusters_df=metric_eval_2.assign_labels_to_clusters(clusters_df,clusters_df.cluster_pred.unique())\n",
    "df_eval = metric_eval_2.get_metrics(clusters_df,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Situation 0\n",
      "Num Clusters:  4\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.3695652173913043\n",
      "Recall:  0.3695652173913043\n",
      "              mis_integration  mis_separation\n",
      "2 cluster(s)                2               2\n",
      "4 cluster(s)                2               2\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 1\n",
      "Num Clusters:  2\n",
      "Num Unique Authors:  2\n",
      "Precision:  0.7386363636363636\n",
      "Recall:  0.6363636363636364\n",
      "              mis_integration  mis_separation\n",
      "2 cluster(s)                2               2\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 2\n",
      "Num Clusters:  3\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.4240601503759398\n",
      "Recall:  0.5142857142857142\n",
      "              mis_integration  mis_separation\n",
      "2 cluster(s)                3               3\n",
      "3 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 3\n",
      "Num Clusters:  4\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.3993359357472966\n",
      "Recall:  0.39215686274509803\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)                1               2\n",
      "2 cluster(s)                1               1\n",
      "4 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 4\n",
      "Num Clusters:  4\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.5\n",
      "Recall:  0.5\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)                1               1\n",
      "2 cluster(s)                1               1\n",
      "3 cluster(s)                2               2\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 5\n",
      "Num Clusters:  4\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.4147069802164987\n",
      "Recall:  0.44680851063829785\n",
      "              mis_integration  mis_separation\n",
      "2 cluster(s)                1               1\n",
      "3 cluster(s)                3               3\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 6\n",
      "Num Clusters:  4\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.47619047619047616\n",
      "Recall:  0.47619047619047616\n",
      "              mis_integration  mis_separation\n",
      "2 cluster(s)                3               3\n",
      "4 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 7\n",
      "Num Clusters:  2\n",
      "Num Unique Authors:  2\n",
      "Precision:  0.375\n",
      "Recall:  0.375\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)                1               1\n",
      "2 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 8\n",
      "Num Clusters:  2\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.45138888888888895\n",
      "Recall:  0.475\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)                1               2\n",
      "2 cluster(s)                2               2\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 9\n",
      "Num Clusters:  2\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.30099759201926385\n",
      "Recall:  0.4166666666666667\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)              NaN             1.0\n",
      "2 cluster(s)              3.0             3.0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 10\n",
      "Num Clusters:  4\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.6590909090909091\n",
      "Recall:  0.6590909090909091\n",
      "              mis_integration  mis_separation\n",
      "2 cluster(s)                2               2\n",
      "3 cluster(s)                2               2\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 11\n",
      "Num Clusters:  3\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.512998712998713\n",
      "Recall:  0.5135135135135135\n",
      "              mis_integration  mis_separation\n",
      "2 cluster(s)                1               1\n",
      "3 cluster(s)                3               3\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 12\n",
      "Num Clusters:  4\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.36150943396226415\n",
      "Recall:  0.3584905660377358\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)              NaN             1.0\n",
      "2 cluster(s)              1.0             1.0\n",
      "3 cluster(s)              1.0             1.0\n",
      "4 cluster(s)              1.0             1.0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 13\n",
      "Num Clusters:  4\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.6096207215541165\n",
      "Recall:  0.48936170212765956\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)                1               2\n",
      "2 cluster(s)                1               1\n",
      "4 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 14\n",
      "Num Clusters:  2\n",
      "Num Unique Authors:  2\n",
      "Precision:  0.7037037037037037\n",
      "Recall:  0.7037037037037037\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)                1               1\n",
      "2 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 15\n",
      "Num Clusters:  4\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.4597928436911488\n",
      "Recall:  0.4576271186440678\n",
      "              mis_integration  mis_separation\n",
      "2 cluster(s)                3               3\n",
      "4 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 16\n",
      "Num Clusters:  4\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.20121951219512196\n",
      "Recall:  0.24390243902439024\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)              NaN             2.0\n",
      "2 cluster(s)              2.0             1.0\n",
      "4 cluster(s)              1.0             1.0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 17\n",
      "Num Clusters:  4\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.7044775400038558\n",
      "Recall:  0.6923076923076923\n",
      "              mis_integration  mis_separation\n",
      "3 cluster(s)                3               3\n",
      "4 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 18\n",
      "Num Clusters:  3\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.5140025990903184\n",
      "Recall:  0.4222222222222222\n",
      "              mis_integration  mis_separation\n",
      "2 cluster(s)                2               2\n",
      "3 cluster(s)                2               2\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 19\n",
      "Num Clusters:  3\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.3753086419753086\n",
      "Recall:  0.4444444444444444\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)              NaN             1.0\n",
      "2 cluster(s)              1.0             1.0\n",
      "3 cluster(s)              2.0             2.0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 20\n",
      "Num Clusters:  3\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.49826989619377166\n",
      "Recall:  0.5588235294117647\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)                1               1\n",
      "2 cluster(s)                2               2\n",
      "3 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 21\n",
      "Num Clusters:  2\n",
      "Num Unique Authors:  2\n",
      "Precision:  0.75\n",
      "Recall:  0.75\n",
      "              mis_integration  mis_separation\n",
      "2 cluster(s)                2               2\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 22\n",
      "Num Clusters:  3\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.14259086672879778\n",
      "Recall:  0.24324324324324326\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)                1               3\n",
      "3 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 23\n",
      "Num Clusters:  2\n",
      "Num Unique Authors:  2\n",
      "Precision:  0.6190476190476191\n",
      "Recall:  0.6190476190476191\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)                1               1\n",
      "2 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 24\n",
      "Num Clusters:  3\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.3576923076923077\n",
      "Recall:  0.38461538461538464\n",
      "              mis_integration  mis_separation\n",
      "2 cluster(s)                2               2\n",
      "3 cluster(s)                2               2\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 25\n",
      "Num Clusters:  3\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.36753305973552214\n",
      "Recall:  0.4186046511627907\n",
      "              mis_integration  mis_separation\n",
      "2 cluster(s)                1               1\n",
      "3 cluster(s)                3               3\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 26\n",
      "Num Clusters:  2\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.2262672811059908\n",
      "Recall:  0.4\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)                1               2\n",
      "2 cluster(s)                2               2\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 27\n",
      "Num Clusters:  3\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.3026315789473684\n",
      "Recall:  0.3611111111111111\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)                1               1\n",
      "2 cluster(s)                1               1\n",
      "3 cluster(s)                2               2\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 28\n",
      "Num Clusters:  5\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.4241379310344828\n",
      "Recall:  0.39655172413793105\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)                1               1\n",
      "2 cluster(s)                1               1\n",
      "3 cluster(s)                1               1\n",
      "4 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 29\n",
      "Num Clusters:  3\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.25413533834586466\n",
      "Recall:  0.3142857142857143\n",
      "              mis_integration  mis_separation\n",
      "2 cluster(s)                2               2\n",
      "3 cluster(s)                2               2\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 30\n",
      "Num Clusters:  4\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.5151515151515151\n",
      "Recall:  0.5151515151515151\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)                1               1\n",
      "2 cluster(s)                1               1\n",
      "3 cluster(s)                2               2\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 31\n",
      "Num Clusters:  5\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.568\n",
      "Recall:  0.52\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)                1               1\n",
      "2 cluster(s)                1               1\n",
      "4 cluster(s)                2               2\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 32\n",
      "Num Clusters:  3\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.3341238471673254\n",
      "Recall:  0.41304347826086957\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)                1               1\n",
      "2 cluster(s)                1               1\n",
      "3 cluster(s)                2               2\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 33\n",
      "Num Clusters:  3\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.47246376811594204\n",
      "Recall:  0.5652173913043478\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)                1               2\n",
      "2 cluster(s)                1               1\n",
      "3 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 34\n",
      "Num Clusters:  2\n",
      "Num Unique Authors:  2\n",
      "Precision:  0.5384615384615384\n",
      "Recall:  0.5384615384615384\n",
      "              mis_integration  mis_separation\n",
      "2 cluster(s)                2               2\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 35\n",
      "Num Clusters:  4\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.4114942528735632\n",
      "Recall:  0.46551724137931033\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)                1               1\n",
      "3 cluster(s)                2               2\n",
      "4 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 36\n",
      "Num Clusters:  5\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.5936147186147186\n",
      "Recall:  0.5227272727272727\n",
      "              mis_integration  mis_separation\n",
      "2 cluster(s)                1               1\n",
      "3 cluster(s)                2               2\n",
      "4 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 37\n",
      "Num Clusters:  3\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.4209150326797386\n",
      "Recall:  0.49019607843137253\n",
      "              mis_integration  mis_separation\n",
      "2 cluster(s)                2               2\n",
      "3 cluster(s)                2               2\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 38\n",
      "Num Clusters:  4\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.5987118531623177\n",
      "Recall:  0.5147058823529411\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)                1               1\n",
      "3 cluster(s)                3               3\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 39\n",
      "Num Clusters:  3\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.5381623723869713\n",
      "Recall:  0.48484848484848486\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)                1               1\n",
      "2 cluster(s)                2               2\n",
      "3 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 40\n",
      "Num Clusters:  4\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.6726190476190477\n",
      "Recall:  0.5833333333333334\n",
      "              mis_integration  mis_separation\n",
      "2 cluster(s)                1               1\n",
      "3 cluster(s)                2               2\n",
      "4 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 41\n",
      "Num Clusters:  4\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.36046511627906974\n",
      "Recall:  0.37209302325581395\n",
      "              mis_integration  mis_separation\n",
      "2 cluster(s)                2               2\n",
      "3 cluster(s)                1               1\n",
      "4 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 42\n",
      "Num Clusters:  3\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.5770687645687645\n",
      "Recall:  0.5\n",
      "              mis_integration  mis_separation\n",
      "2 cluster(s)                2               2\n",
      "3 cluster(s)                2               2\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 43\n",
      "Num Clusters:  3\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.4532085561497326\n",
      "Recall:  0.5\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)              NaN             1.0\n",
      "2 cluster(s)              2.0             2.0\n",
      "3 cluster(s)              1.0             1.0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 44\n",
      "Num Clusters:  4\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.6529080675422139\n",
      "Recall:  0.5121951219512195\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)                2               2\n",
      "3 cluster(s)                1               1\n",
      "4 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 45\n",
      "Num Clusters:  3\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.3855128828390861\n",
      "Recall:  0.45454545454545453\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)                1               1\n",
      "2 cluster(s)                2               2\n",
      "3 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 46\n",
      "Num Clusters:  3\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.1997983870967742\n",
      "Recall:  0.3\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)                1               2\n",
      "2 cluster(s)                1               1\n",
      "3 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 47\n",
      "Num Clusters:  3\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.46981952864305804\n",
      "Recall:  0.5675675675675675\n",
      "              mis_integration  mis_separation\n",
      "1 cluster(s)                1               1\n",
      "2 cluster(s)                2               2\n",
      "3 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 48\n",
      "Num Clusters:  4\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.394489247311828\n",
      "Recall:  0.3709677419354839\n",
      "              mis_integration  mis_separation\n",
      "2 cluster(s)                2               2\n",
      "3 cluster(s)                1               1\n",
      "4 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "Situation 49\n",
      "Num Clusters:  4\n",
      "Num Unique Authors:  4\n",
      "Precision:  0.570562435500516\n",
      "Recall:  0.5789473684210527\n",
      "              mis_integration  mis_separation\n",
      "2 cluster(s)                2               2\n",
      "3 cluster(s)                1               1\n",
      "4 cluster(s)                1               1\n",
      "\n",
      "-------------------\n",
      "\n",
      "\n",
      "\n",
      "Total Precision: 0.46442926067453877\tTotal Recall: 0.4760500573268133\n",
      "                 2 cluster(s)  3 cluster(s)  4 cluster(s)\n",
      "mis_integration      0.272727      0.666667      0.060606\n",
      "mis_separation       0.272727      0.666667      0.060606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47016786427204743"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metric_eval_2.get_metrics_many(y_hat_comb)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMDB4SeVJCVxRCeLtwZTVEo",
   "include_colab_link": true,
   "name": "Untitled10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
